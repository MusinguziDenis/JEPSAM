{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d561bf6-b777-4f72-8632-d0ee7ab53273",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:08.008021Z",
     "iopub.status.busy": "2023-06-27T03:54:08.007803Z",
     "iopub.status.idle": "2023-06-27T03:54:08.176285Z",
     "shell.execute_reply": "2023-06-27T03:54:08.173972Z",
     "shell.execute_reply.started": "2023-06-27T03:54:08.008000Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 27 05:54:08 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   62C    P0    25W /  N/A |    541MiB /  6069MiB |      3%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1377      G   /usr/lib/xorg/Xorg                 59MiB |\n",
      "|    0   N/A  N/A      2371      G   /usr/lib/xorg/Xorg                220MiB |\n",
      "|    0   N/A  N/A      3004      G   /usr/bin/gnome-shell               68MiB |\n",
      "|    0   N/A  N/A      3245      G   /opt/freedownloadmanager/fdm       17MiB |\n",
      "|    0   N/A  N/A      4549      G   ...RendererForSitePerProcess       39MiB |\n",
      "|    0   N/A  N/A      7104      G   ...RendererForSitePerProcess       36MiB |\n",
      "|    0   N/A  N/A    956091      G   ...wnloads/Telegram/Telegram        2MiB |\n",
      "|    0   N/A  N/A   1118088      G   ...097899844649983794,131072       85MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5235aa13-39f5-4748-a523-13e493063ca2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:08.179548Z",
     "iopub.status.busy": "2023-06-27T03:54:08.178859Z",
     "iopub.status.idle": "2023-06-27T03:54:08.223044Z",
     "shell.execute_reply": "2023-06-27T03:54:08.220861Z",
     "shell.execute_reply.started": "2023-06-27T03:54:08.179476Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed9ac595-8c04-4dd1-bb57-a847b372bcc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:08.225581Z",
     "iopub.status.busy": "2023-06-27T03:54:08.224802Z",
     "iopub.status.idle": "2023-06-27T03:54:09.915986Z",
     "shell.execute_reply": "2023-06-27T03:54:09.915337Z",
     "shell.execute_reply.started": "2023-06-27T03:54:08.225539Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from addict import Dict\n",
    "\n",
    "import copy\n",
    "\n",
    "from einops import rearrange\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from torchinfo import summary\n",
    "import torchvision.models as torchvision_models\n",
    "\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba2fd49f-5557-47bb-a60b-e4a44b9cfb93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:09.918265Z",
     "iopub.status.busy": "2023-06-27T03:54:09.917918Z",
     "iopub.status.idle": "2023-06-27T03:54:09.941377Z",
     "shell.execute_reply": "2023-06-27T03:54:09.940746Z",
     "shell.execute_reply.started": "2023-06-27T03:54:09.918241Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zeusdric/jepsam/repo/AEJEPS\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "\n",
    "sys.path.append(\"src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1be02207-6411-467c-b8c1-7c49d94269ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:09.942483Z",
     "iopub.status.busy": "2023-06-27T03:54:09.942231Z",
     "iopub.status.idle": "2023-06-27T03:54:10.791153Z",
     "shell.execute_reply": "2023-06-27T03:54:10.790346Z",
     "shell.execute_reply.started": "2023-06-27T03:54:09.942461Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeusdric/miniconda3/envs/jeps/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "from utils.parser import load_config, parse_args\n",
    "import utils.model_utils as model_utils\n",
    "from utils.ae_resnet import get_configs, ResNetEncoder, ResNetDecoder\n",
    "\n",
    "from dataloader import get_dataloaders, SimpleTokenizer, JEPSAMDataset\n",
    "import vocabulary as vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8530e2bd-2a8a-4a73-8060-eff13096f5eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:10.792335Z",
     "iopub.status.busy": "2023-06-27T03:54:10.791988Z",
     "iopub.status.idle": "2023-06-27T03:54:10.830548Z",
     "shell.execute_reply": "2023-06-27T03:54:10.829958Z",
     "shell.execute_reply.started": "2023-06-27T03:54:10.792312Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg = load_config(config_file_path=\"configs/aejeps_cfg.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c82e46d7-9cdb-4a64-a6a3-b715f1ce2fcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:10.831599Z",
     "iopub.status.busy": "2023-06-27T03:54:10.831284Z",
     "iopub.status.idle": "2023-06-27T03:54:10.972344Z",
     "shell.execute_reply": "2023-06-27T03:54:10.970139Z",
     "shell.execute_reply.started": "2023-06-27T03:54:10.831561Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EMBEDDING_DIM': 256,\n",
       " 'HIDDEN_DIM': 256,\n",
       " 'CNN_FC_DIM': 256,\n",
       " 'NUM_LAYERS_ENCODER': 2,\n",
       " 'BATCH_FIRST': True,\n",
       " 'ENCODER_DROPOUT': 0.35,\n",
       " 'IS_BIDIRECTIONAL': True,\n",
       " 'NUM_LAYERS_MOTOR': 1,\n",
       " 'ACTIVATION_MOTOR': 'LeakyReLU',\n",
       " 'MOTOR_DROPOUT': 0.25,\n",
       " 'NUM_LAYERS_LANG': 2,\n",
       " 'ACTIVATION_LANG': 'LeakyReLU',\n",
       " 'LANG_DROPOUT': 0.25,\n",
       " 'HIDDEN_TO_CONV': 1024,\n",
       " 'DECODER_ACTIVATION': 'Sigmoid'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.AEJEPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c536fa-d925-4e7b-82fb-f8a9e9f41e72",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Get batch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8e03678-e1f7-495a-b391-0a2444fd4637",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:10.976514Z",
     "iopub.status.busy": "2023-06-27T03:54:10.975748Z",
     "iopub.status.idle": "2023-06-27T03:54:11.069627Z",
     "shell.execute_reply": "2023-06-27T03:54:11.068959Z",
     "shell.execute_reply.started": "2023-06-27T03:54:10.976446Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../dataset/'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.DATASET.PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c442393-c348-4a85-b7c7-48156ca9a766",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:11.070546Z",
     "iopub.status.busy": "2023-06-27T03:54:11.070332Z",
     "iopub.status.idle": "2023-06-27T03:54:11.246402Z",
     "shell.execute_reply": "2023-06-27T03:54:11.245438Z",
     "shell.execute_reply.started": "2023-06-27T03:54:11.070526Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_ID</th>\n",
       "      <th>in_state</th>\n",
       "      <th>goal_state</th>\n",
       "      <th>validator</th>\n",
       "      <th>action_description</th>\n",
       "      <th>motor_cmd</th>\n",
       "      <th>len_action_desc</th>\n",
       "      <th>len_motor_cmd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>amihretu</td>\n",
       "      <td>put the :BOTTLE to the left of :BOTTLE</td>\n",
       "      <td>:BOTTLE BLUE POSE-9 :BOTTLE RED POSE-2 :BOTTLE...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1011</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>amihretu</td>\n",
       "      <td>move the :BOTTLE left</td>\n",
       "      <td>:BOTTLE BLUE POSE-3 :BOTTLE  #'*leftward-trans...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1012</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>amihretu</td>\n",
       "      <td>put the :BOTTLE to the right of :MUG</td>\n",
       "      <td>:BOTTLE BLUE POSE-7 :MUG RED POSE-3 :BOTTLE  #...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1013</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>amihretu</td>\n",
       "      <td>shift the :CUP backwards</td>\n",
       "      <td>:CUP RED POSE-4 :CUP  #'*backward-transformati...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>amihretu</td>\n",
       "      <td>shift the :BOTTLE forwards</td>\n",
       "      <td>:BOTTLE GREEN POSE-3 :BOTTLE  #'*forward-trans...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_ID  in_state  goal_state validator  \\\n",
       "0       1005         0           9  amihretu   \n",
       "1       1011         0           9  amihretu   \n",
       "2       1012         0           9  amihretu   \n",
       "3       1013         0           9  amihretu   \n",
       "4       1015         0           9  amihretu   \n",
       "\n",
       "                       action_description  \\\n",
       "0  put the :BOTTLE to the left of :BOTTLE   \n",
       "1                   move the :BOTTLE left   \n",
       "2    put the :BOTTLE to the right of :MUG   \n",
       "3                shift the :CUP backwards   \n",
       "4              shift the :BOTTLE forwards   \n",
       "\n",
       "                                           motor_cmd  len_action_desc  \\\n",
       "0  :BOTTLE BLUE POSE-9 :BOTTLE RED POSE-2 :BOTTLE...                8   \n",
       "1  :BOTTLE BLUE POSE-3 :BOTTLE  #'*leftward-trans...                4   \n",
       "2  :BOTTLE BLUE POSE-7 :MUG RED POSE-3 :BOTTLE  #...                8   \n",
       "3  :CUP RED POSE-4 :CUP  #'*backward-transformati...                4   \n",
       "4  :BOTTLE GREEN POSE-3 :BOTTLE  #'*forward-trans...                4   \n",
       "\n",
       "   len_motor_cmd  \n",
       "0             11  \n",
       "1              8  \n",
       "2             11  \n",
       "3              8  \n",
       "4              8  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf = pd.read_csv(\n",
    "    osp.join(cfg.DATASET.PATH, \"updated_train.csv\")\n",
    ")\n",
    "\n",
    "tdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc87452a-62ca-4e3e-bf3d-3636c4213e9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:11.247887Z",
     "iopub.status.busy": "2023-06-27T03:54:11.247512Z",
     "iopub.status.idle": "2023-06-27T03:54:11.297075Z",
     "shell.execute_reply": "2023-06-27T03:54:11.296191Z",
     "shell.execute_reply.started": "2023-06-27T03:54:11.247858Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Prepared 1367 training samples and 605 validation samples \n"
     ]
    }
   ],
   "source": [
    "train_dl, _ = get_dataloaders(\n",
    "    train_df=tdf,\n",
    "    cfg=cfg,\n",
    "    # dataset_module=JEPSAMDataset\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38f1ba91-7409-4338-8c69-b2eff8d2435d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:11.298057Z",
     "iopub.status.busy": "2023-06-27T03:54:11.297733Z",
     "iopub.status.idle": "2023-06-27T03:54:13.218082Z",
     "shell.execute_reply": "2023-06-27T03:54:13.217329Z",
     "shell.execute_reply.started": "2023-06-27T03:54:11.298035Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for data in train_dl:\n",
    "#     s_id, in_state, goal_state, ad, cmd = data['sample_id'], data[\n",
    "#         'in_state'], data['goal_state'], data['action_desc'], data[\"motor_cmd\"]\n",
    "#     print(\"In\\t\\t:\", in_state.shape)\n",
    "#     print(\"Goal\\t\\t:\", goal_state.shape)\n",
    "#     print(\"Action desc\\t:\", ad[\"ids\"].shape)\n",
    "#     print(\"Action desc (len)\\t:\", ad[\"length\"].shape)\n",
    "\n",
    "#     print(\"CMD\\t\\t:\", cmd[\"ids\"].shape)\n",
    "#     print(\"CMD(len)\\t\\t:\", cmd[\"length\"].shape)\n",
    "    pass\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78fc13ec-5389-4329-8ba4-1aaa9dc6e737",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:13.219602Z",
     "iopub.status.busy": "2023-06-27T03:54:13.219297Z",
     "iopub.status.idle": "2023-06-27T03:54:13.254418Z",
     "shell.execute_reply": "2023-06-27T03:54:13.253591Z",
     "shell.execute_reply.started": "2023-06-27T03:54:13.219580Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "in_state, goal_state, ad, cmd, ad_lens, cmd_lens = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5206e90-41b1-48eb-8c09-0020f64748e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:13.258625Z",
     "iopub.status.busy": "2023-06-27T03:54:13.258285Z",
     "iopub.status.idle": "2023-06-27T03:54:13.393356Z",
     "shell.execute_reply": "2023-06-27T03:54:13.390922Z",
     "shell.execute_reply.started": "2023-06-27T03:54:13.258600Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 224, 224]),\n",
       " torch.Size([2, 3, 224, 224]),\n",
       " torch.Size([2, 1, 7]),\n",
       " torch.Size([2, 1, 11]),\n",
       " torch.Size([2]),\n",
       " torch.Size([2]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_state.shape, goal_state.shape, ad.shape, cmd.shape, ad_lens.shape, cmd_lens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a5628c1-0de1-4d9e-9e4c-587bc34c6fea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:13.397097Z",
     "iopub.status.busy": "2023-06-27T03:54:13.395968Z",
     "iopub.status.idle": "2023-06-27T03:54:13.474058Z",
     "shell.execute_reply": "2023-06-27T03:54:13.471834Z",
     "shell.execute_reply.started": "2023-06-27T03:54:13.397023Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[48,  5, 28, 42, 14, 27, 39,  5,  0, 14, 46]],\n",
       "\n",
       "        [[48,  5, 28, 38,  5,  2,  5, 46, 47, 47, 47]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9842dfe-7e5a-42da-a6f7-b9570ec415ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97584da1-6cf4-43db-b91f-3ae19024ae32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:13.479194Z",
     "iopub.status.busy": "2023-06-27T03:54:13.478244Z",
     "iopub.status.idle": "2023-06-27T03:54:13.598856Z",
     "shell.execute_reply": "2023-06-27T03:54:13.597899Z",
     "shell.execute_reply.started": "2023-06-27T03:54:13.479120Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "# tt = PreTrainedTokenizerFast(\n",
    "#     tokenizer_file=cfg.DATASET.TOKENIZER_PATH, # You can load from the tokenizer file, alternatively\n",
    "#     unk_token=\"[UNK]\",\n",
    "#     pad_token=\"[PAD]\",\n",
    "#     cls_token=\"[CLS]\",\n",
    "#     sep_token=\"[SEP]\",\n",
    "#     mask_token=\"[MASK]\",\n",
    "# )\n",
    "\n",
    "\n",
    "tt = SimpleTokenizer(vocab=vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dfe9c4d-93ea-4d1b-98f8-ff6df889d818",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:13.600306Z",
     "iopub.status.busy": "2023-06-27T03:54:13.599964Z",
     "iopub.status.idle": "2023-06-27T03:54:13.719035Z",
     "shell.execute_reply": "2023-06-27T03:54:13.716812Z",
     "shell.execute_reply.started": "2023-06-27T03:54:13.600274Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# _, in_state, goal_state, ad, cmd = data['sample_id'], data['in_state'], data['goal_state'], data['action_desc'], data[\"motor_cmd\"]\n",
    "\n",
    "# ad[\"ids\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2101500-0b1e-4358-9beb-55816a766de4",
   "metadata": {},
   "source": [
    "## Model refectoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13480e66-708a-418a-84c3-9529d9398d00",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b847ce-3279-4fc7-9fa5-2137794772ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### CNN backbone builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21746089-b99a-4b32-9cac-6b7336f1e468",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0d6e9c9-89e0-404f-8d7c-b01a15ce79bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:13.721977Z",
     "iopub.status.busy": "2023-06-27T03:54:13.721297Z",
     "iopub.status.idle": "2023-06-27T03:54:13.803693Z",
     "shell.execute_reply": "2023-06-27T03:54:13.801862Z",
     "shell.execute_reply.started": "2023-06-27T03:54:13.721911Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# b = model_utils.get_cnn_backbone(cfg=cfg, fc_out=512)\n",
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d32eadb-4f4d-49e6-8716-f45b406a9d49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8897e77-75e0-4236-8fe8-133b5553a0fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:13.807516Z",
     "iopub.status.busy": "2023-06-27T03:54:13.805675Z",
     "iopub.status.idle": "2023-06-27T03:54:13.918602Z",
     "shell.execute_reply": "2023-06-27T03:54:13.916438Z",
     "shell.execute_reply.started": "2023-06-27T03:54:13.807442Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# xx = torch.randn((1, 3, 224, 224))\n",
    "\n",
    "# xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46cc321f-8bd9-44ff-b694-5ab30bf9181c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:13.922082Z",
     "iopub.status.busy": "2023-06-27T03:54:13.921389Z",
     "iopub.status.idle": "2023-06-27T03:54:14.077301Z",
     "shell.execute_reply": "2023-06-27T03:54:14.075124Z",
     "shell.execute_reply.started": "2023-06-27T03:54:13.922016Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668289b9-8275-4e83-ab17-0790d843aa9e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### JEPSAM encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15c0e95f-9b52-4d8d-ac2b-673020ebbd16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:14.080614Z",
     "iopub.status.busy": "2023-06-27T03:54:14.079919Z",
     "iopub.status.idle": "2023-06-27T03:54:14.268926Z",
     "shell.execute_reply": "2023-06-27T03:54:14.266924Z",
     "shell.execute_reply.started": "2023-06-27T03:54:14.080549Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class JEPSAMEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        cfg: Dict, \n",
    "        cnn_backbone_name:str=\"resnet50\"\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.cfg = cfg\n",
    "        \n",
    "        self.device = self.cfg.TRAIN.GPU_DEVICE if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        # embedding layer\n",
    "        self.embedding = nn.Embedding(cfg.DATASET.VOCABULARY_SIZE, cfg.AEJEPS.EMBEDDING_DIM)        \n",
    "        \n",
    "        # CNN ftr extractor\n",
    "        configs, bottleneck = get_configs(cnn_backbone_name)\n",
    "\n",
    "        self.image_feature_extractor = nn.Sequential(\n",
    "            ResNetEncoder(configs, bottleneck),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features = 2048*7*7, out_features=cfg.AEJEPS.CNN_FC_DIM)\n",
    "        )\n",
    "        \n",
    "        # features mixer\n",
    "        self.feature_mixing = nn.LSTM(\n",
    "            input_size=cfg.AEJEPS.EMBEDDING_DIM, \n",
    "            hidden_size=cfg.AEJEPS.HIDDEN_DIM, \n",
    "            num_layers=cfg.AEJEPS.NUM_LAYERS_ENCODER,\n",
    "            dropout=cfg.AEJEPS.ENCODER_DROPOUT, \n",
    "            bidirectional=cfg.AEJEPS.IS_BIDIRECTIONAL\n",
    "        )\n",
    "                \n",
    "        self.to(self.device)\n",
    "        \n",
    "        \n",
    "    def forward(self, inp:Union[List, list, dict], mode:str='train'):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        if isinstance(inp, list) or isinstance(inp, List):\n",
    "            in_state, goal_state, ad, cmd, ad_lens, cmd_lens = inp\n",
    "        else:\n",
    "            _, in_state, goal_state, ad, cmd = inp['sample_id'], inp['in_state'], inp['goal_state'], inp['action_desc'], inp[\"motor_cmd\"]\n",
    "            ad = ad[\"ids\"]\n",
    "            # print(ad[\"length\"])\n",
    "            ad_lens = ad[\"length\"]\n",
    "            \n",
    "            cmd = cmd[\"ids\"]\n",
    "            cmd_lens = cmd[\"length\"]\n",
    "        \n",
    "        in_state, goal_state, ad, cmd, ad_lens, cmd_lens = in_state.to(self.device), goal_state.to(self.device), ad.to(self.device), cmd.to(self.device), ad_lens.to(self.device), cmd_lens.to(self.device)\n",
    "        # print(in_state.device)\n",
    "        B, _, max_len = ad.shape\n",
    "\n",
    "        # 1. Image feature extraction\n",
    "        feats_per = self.image_feature_extractor(in_state)\n",
    "        # feats_per = self.img_projection(feats_per.view(B, -1))\n",
    "        # print(feats_per.shape)\n",
    "        feats_per = feats_per.repeat((1, max_len)).reshape((B, max_len, -1))\n",
    "        \n",
    "        if mode ==\"train\":\n",
    "            feats_goal = self.image_feature_extractor(goal_state)\n",
    "            # feats_goal = self.img_projection(feats_goal.view(B, -1))\n",
    "            # print(feats_goal.shape)\n",
    "            \n",
    "            feats_goal = feats_goal.repeat((1, max_len)).reshape((B, max_len, -1))\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        # print(f\"feats_per: {feats_per.shape}\")\n",
    "        # print(f\"feats_goal: {feats_goal.shape}\")\n",
    "        \n",
    "        # 2. Text feature extraction\n",
    "        action_desc_emb = self.embedding(ad)#.squeeze(1)\n",
    "        \n",
    "        if mode ==\"train\":\n",
    "            motor_cmd_emb = self.embedding(cmd)#.squeeze(1)\n",
    "            # For each batch entry determine the length of the longest of the text sequence\n",
    "            lengths_max = [max(ltext, lcmd)\n",
    "                           for ltext, lcmd in zip(ad_lens, cmd_lens)]        \n",
    "            # print(lengths_max)\n",
    "        else:\n",
    "            lengths_max = [ltext for ltext in ad_lens]     \n",
    "        # 3. Feature Fusion\n",
    "        # Optional: add a projection layer that will \n",
    "        # print(feats_per.shape, feats_goal.shape, action_desc_emb.shape, motor_cmd_emb.shape)\n",
    "        \n",
    "        # print( \n",
    "        #     feats_per.shape, \n",
    "        #     feats_goal.shape, \n",
    "        #     action_desc_emb.squeeze(1).shape, \n",
    "        #     motor_cmd_emb.squeeze(1).shape\n",
    "        #      )\n",
    "        concat_feats = torch.cat((\n",
    "            feats_per, \n",
    "            feats_goal, \n",
    "            action_desc_emb.squeeze(1), \n",
    "            motor_cmd_emb.squeeze(1)\n",
    "        ), dim=-2)#.squeeze(1)\n",
    "        \n",
    "        # print(f\"Fused feats: {concat_feats.shape}\")\n",
    "        \n",
    "        # 4. Feature mixing\n",
    "        # packed_input = concat_feats\n",
    "        packed_input = pack_padded_sequence(\n",
    "            input=concat_feats, \n",
    "            lengths=lengths_max, \n",
    "            enforce_sorted=False, \n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        output, (hidden, carousel) = self.feature_mixing(packed_input)\n",
    "        # print(output.shape)\n",
    "        output, len_output = pad_packed_sequence(output, batch_first= True)\n",
    "        \n",
    "        return output, len_output, hidden, carousel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2cd0af-dbd5-42cb-a296-e97ff547c0d0",
   "metadata": {},
   "source": [
    "### Encoder summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51cfedb8-0dfb-4ceb-a39e-3b271039247a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:14.272928Z",
     "iopub.status.busy": "2023-06-27T03:54:14.271744Z",
     "iopub.status.idle": "2023-06-27T03:54:15.795440Z",
     "shell.execute_reply": "2023-06-27T03:54:15.794496Z",
     "shell.execute_reply.started": "2023-06-27T03:54:14.272850Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc out:  torch.Size([2, 11, 512])\n"
     ]
    }
   ],
   "source": [
    "encoder = JEPSAMEncoder(\n",
    "    cnn_backbone_name=\"resnet50\",\n",
    "    cfg=cfg\n",
    ")\n",
    "\n",
    "o, lo, h, c = encoder(data)\n",
    "\n",
    "print(\"enc out: \", o.shape)\n",
    "\n",
    "# # model summary\n",
    "# summary(\n",
    "#     model=encoder,\n",
    "#     input_dict=data,\n",
    "#     col_names=[\"kernel_size\", \"num_params\"],\n",
    "\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5016b85-5211-45b1-8a31-174e8bae82fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4917a5c8-01f8-4a97-b70f-a7177c7c5a5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:15.797111Z",
     "iopub.status.busy": "2023-06-27T03:54:15.796859Z",
     "iopub.status.idle": "2023-06-27T03:54:15.842073Z",
     "shell.execute_reply": "2023-06-27T03:54:15.841239Z",
     "shell.execute_reply.started": "2023-06-27T03:54:15.797089Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class JEPSAMDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        cfg: Dict,\n",
    "        cnn_backbone_name:str=\"resnet50\",\n",
    "        \n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # class attributes\n",
    "        self.cfg = cfg\n",
    "        self.cnn_backbone_name = cnn_backbone_name\n",
    "        self.num_directions = 2 if cfg.AEJEPS.IS_BIDIRECTIONAL else 1\n",
    "        decoder_hidden_dim = self.num_directions * cfg.AEJEPS.HIDDEN_DIM\n",
    "        \n",
    "        ## Layers\n",
    "        # tokenizer \n",
    "        # self.tokenizer  = PreTrainedTokenizerFast(\n",
    "        #     tokenizer_file= self.cfg.DATASET.TOKENIZER_PATH, # You can load from the tokenizer file, alternatively\n",
    "        #     unk_token=\"[UNK]\",\n",
    "        #     pad_token=\"[PAD]\",\n",
    "        #     cls_token=\"[CLS]\",\n",
    "        #     sep_token=\"[SEP]\",\n",
    "        #     mask_token=\"[MASK]\",\n",
    "        # )\n",
    "        \n",
    "        self.tokenizer = SimpleTokenizer(vocab)\n",
    "\n",
    "        # embedding layer - same as encoder embedding layer\n",
    "        self.embedding = nn.Embedding(\n",
    "            cfg.DATASET.VOCABULARY_SIZE, \n",
    "            cfg.AEJEPS.EMBEDDING_DIM,\n",
    "            device=self.cfg.TRAIN.GPU_DEVICE\n",
    "        )\n",
    "        \n",
    "        # image decoder\n",
    "        configs, bottleneck = get_configs(cnn_backbone_name)\n",
    "        self.img_projection = nn.Sequential(\n",
    "            nn.Linear(in_features=decoder_hidden_dim, out_features=cfg.AEJEPS.CNN_FC_DIM ),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=cfg.AEJEPS.CNN_FC_DIM , out_features=2048*7*7),\n",
    "        ).to(self.cfg.TRAIN.GPU_DEVICE)\n",
    "        \n",
    "        self.img_decoder = ResNetDecoder(configs[::-1], bottleneck).to(self.cfg.TRAIN.GPU_DEVICE)\n",
    "        \n",
    "        # motor command decoding layer\n",
    "        self.motor_decoder = nn.LSTMCell(\n",
    "            input_size=cfg.AEJEPS.EMBEDDING_DIM, \n",
    "            hidden_size=decoder_hidden_dim \n",
    "        ).to(self.cfg.TRAIN.GPU_DEVICE)\n",
    "        \n",
    "        # action desc. decoding layer\n",
    "        self.lang_decoder = nn.LSTMCell(\n",
    "            input_size=cfg.AEJEPS.EMBEDDING_DIM, \n",
    "            hidden_size=decoder_hidden_dim\n",
    "        ).to(self.cfg.TRAIN.GPU_DEVICE)\n",
    "        \n",
    "        # projection layers\n",
    "        # self.hidden_to_conv_in = nn.Linear(\n",
    "        #     in_features=decoder_hidden_dim, \n",
    "        #     out_features=self.cfg.AEJEPS.HIDDEN_TO_CONV\n",
    "        # )\n",
    "            \n",
    "        self.lang_head = nn.Linear(\n",
    "            in_features=decoder_hidden_dim, \n",
    "            out_features=cfg.DATASET.VOCABULARY_SIZE \n",
    "            # To be discussed use the individual vocabs or the merged one for the projection\n",
    "        ).to(self.cfg.TRAIN.GPU_DEVICE)\n",
    "        self.motor_cmd_head = nn.Linear(\n",
    "            in_features=decoder_hidden_dim, \n",
    "            out_features=cfg.DATASET.VOCABULARY_SIZE \n",
    "            # To be discussed use the individual vocabs or the merged one for the projection\n",
    "        ).to(self.cfg.TRAIN.GPU_DEVICE)\n",
    "        \n",
    "        self.device = self.cfg.TRAIN.GPU_DEVICE if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        enc_output, \n",
    "        len_enc_output, \n",
    "        hidden, \n",
    "        carousel,\n",
    "        mode:str=\"train\"\n",
    "    ):\n",
    "            \n",
    "        batch_size, max_len, num_ftrs = enc_output.shape\n",
    "        \n",
    "        # hidden\n",
    "        # hidden = hidden.view(self.num_directions, self.num_layers, batch_size, -1)\n",
    "        # hidden = hidden[:self.num_directions, self.num_layers - 1, :, :]  # Take the last forward direction hidden state for\n",
    "        \n",
    "        hidden, carousel = self._rearrange_states(hidden, carousel)\n",
    "\n",
    "        cmd_h_t, lang_h_t = (hidden, carousel), (hidden, carousel)\n",
    "            \n",
    "        # Unsqueeze to match expected input by transposed convolutions\n",
    "        self.hidden = hidden.unsqueeze(0)\n",
    "        \n",
    "        # run decoding steps\n",
    "        # generate action desc from latent representation\n",
    "        lang_out = self._decode_action_description(hidden=lang_h_t, batch_size=batch_size, max_len=max_len)\n",
    "        # generate motor cmd from latent representation\n",
    "        motor_out = self._decode_motor_command(hidden=cmd_h_t, batch_size=batch_size, max_len=max_len)\n",
    "        # reconstruct from latent representation\n",
    "        per_image_rec = self._reconstruct_image(hidden)\n",
    "        # generate from latent representation\n",
    "        goal_image = self._generate_goal_image(hidden)\n",
    "        \n",
    "        return per_image_rec, goal_image, lang_out, motor_out\n",
    "    \n",
    "    \n",
    "    def _rearrange_states(self, hidden, carousel):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        # hidden\n",
    "        hidden = rearrange(\n",
    "            hidden, \n",
    "            '(d l) b h -> l b (d h)',\n",
    "            d=self.num_directions, \n",
    "            l=self.cfg.AEJEPS.NUM_LAYERS_ENCODER\n",
    "        )\n",
    "        hidden = hidden[self.cfg.AEJEPS.NUM_LAYERS_ENCODER - 1, :, :]\n",
    "        \n",
    "        # carousel\n",
    "        carousel = rearrange(\n",
    "            carousel, \n",
    "            '(d l) b h -> l b (d h)',\n",
    "             d=self.num_directions, \n",
    "            l=self.cfg.AEJEPS.NUM_LAYERS_ENCODER\n",
    "        )\n",
    "        carousel = carousel[self.cfg.AEJEPS.NUM_LAYERS_ENCODER - 1, :, :]\n",
    "        \n",
    "        return hidden, carousel\n",
    "    \n",
    "    \n",
    "    def _decode_action_description(\n",
    "        self, \n",
    "        hidden, \n",
    "        batch_size:int, \n",
    "        max_len:int\n",
    "    ):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        # print(next(self.lang_decoder.parameters()).is_cuda)\n",
    "        \n",
    "        lang_out = []        \n",
    "        # Initialize the predictions with [SOS]\n",
    "        prediction_txt_t = torch.ones(batch_size, 1).to(self.device).long() * self.cfg.DATASET.SOS\n",
    "        # print(prediction_txt_t.device)\n",
    "        for t in range(max_len):\n",
    "            char = self.embedding(prediction_txt_t).squeeze(1)\n",
    "            # hidden state at time step t for each RNN\n",
    "            hidden, lang_c_t = self.lang_decoder(char, hidden)\n",
    "            # project hidden state to vocab\n",
    "            lang_scores = self.lang_head(hidden)\n",
    "            # update hidden states\n",
    "            hidden = (hidden, lang_c_t)\n",
    "            # store newly generated token\n",
    "            lang_out.append(lang_scores.unsqueeze(1))\n",
    "            # draw new token: greedy decoding\n",
    "            prediction_txt_t = lang_scores.argmax(dim=1)\n",
    "        \n",
    "        return torch.cat(lang_out, 1)\n",
    "            \n",
    "    def _decode_motor_command(\n",
    "        self, \n",
    "        hidden, \n",
    "        batch_size:int, \n",
    "        max_len:int,\n",
    "        method:str=\"embed\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        ----------\n",
    "        \n",
    "            method: str\n",
    "                The method to use for token \n",
    "        \"\"\"\n",
    "        \n",
    "        motor_out = []\n",
    "        # Initialize the predictions with [SOS]\n",
    "        prediction_cmd_t = torch.ones(batch_size, 1).to(self.device).long() * self.cfg.DATASET.SOS\n",
    "            \n",
    "        for t in range(max_len):\n",
    "            if method==\"one-hot\":\n",
    "                command = one_hot(\n",
    "                    prediction_cmd_t.long(),\n",
    "                    num_classes=num_commands\n",
    "                ).squeeze(1).float()\n",
    "            else:\n",
    "                command = self.embedding(prediction_cmd_t).squeeze(1)\n",
    "            \n",
    "            # hidden state at time step t for each RNN\n",
    "            hidden, cmd_c_t = self.motor_decoder(command, hidden)\n",
    "            # project hidden state to vocab\n",
    "            cmd_scores = self.motor_cmd_head(hidden)\n",
    "            # update hidden states\n",
    "            hidden = (hidden, cmd_c_t)\n",
    "            # store newly generated token\n",
    "            motor_out.append(cmd_scores.unsqueeze(1))\n",
    "            # draw new token: greedy decoding\n",
    "            prediction_cmd_t = cmd_scores.argmax(dim=1)\n",
    "            \n",
    "        return torch.cat(motor_out, 1)\n",
    "\n",
    "    def _reconstruct_image(self, hidden):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        conv_in = self.img_projection(hidden)\n",
    "        # print(conv_in.shape)\n",
    "        B, _ = conv_in.shape\n",
    "        \n",
    "        return self.img_decoder(conv_in.view(B, 2048, 7, 7))\n",
    "    \n",
    "    def _generate_goal_image(self, hidden):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return self._reconstruct_image(hidden)# to be fixed\n",
    "\n",
    "    \n",
    "    def pred_to_str(\n",
    "        self, \n",
    "        predictions:torch.Tensor\n",
    "    )->list:\n",
    "        \"\"\"\n",
    "            Decode predictions (from ids to token)\n",
    "            \n",
    "            Parameters:\n",
    "            ----------\n",
    "                - predictions: Tensor\n",
    "                    batch predictions from decoder module\n",
    "        \"\"\"\n",
    "        return self.tokenizer.batch_decode(predictions.argmax(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbee9f8e-cc25-437f-a0fa-e60cbfbea09e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:15.843140Z",
     "iopub.status.busy": "2023-06-27T03:54:15.842874Z",
     "iopub.status.idle": "2023-06-27T03:54:16.470185Z",
     "shell.execute_reply": "2023-06-27T03:54:16.469440Z",
     "shell.execute_reply.started": "2023-06-27T03:54:15.843120Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JEPSAMDecoder(\n",
       "  (embedding): Embedding(65, 256)\n",
       "  (img_projection): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=256, out_features=100352, bias=True)\n",
       "  )\n",
       "  (img_decoder): ResNetDecoder(\n",
       "    (conv1): DecoderBottleneckBlock(\n",
       "      (00 EncoderLayer): DecoderBottleneckLayer(\n",
       "        (weight_layer1): Sequential(\n",
       "          (0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer2): Sequential(\n",
       "          (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer3): Sequential(\n",
       "          (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (01 EncoderLayer): DecoderBottleneckLayer(\n",
       "        (weight_layer1): Sequential(\n",
       "          (0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer2): Sequential(\n",
       "          (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer3): Sequential(\n",
       "          (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (02 EncoderLayer): DecoderBottleneckLayer(\n",
       "        (weight_layer1): Sequential(\n",
       "          (0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer2): Sequential(\n",
       "          (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer3): Sequential(\n",
       "          (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): ConvTranspose2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), output_padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (upsample): Sequential(\n",
       "          (0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): ConvTranspose2d(2048, 1024, kernel_size=(1, 1), stride=(2, 2), output_padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv2): DecoderBottleneckBlock(\n",
       "      (00 EncoderLayer): DecoderBottleneckLayer(\n",
       "        (weight_layer1): Sequential(\n",
       "          (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer2): Sequential(\n",
       "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer3): Sequential(\n",
       "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (01 EncoderLayer): DecoderBottleneckLayer(\n",
       "        (weight_layer1): Sequential(\n",
       "          (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer2): Sequential(\n",
       "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer3): Sequential(\n",
       "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (02 EncoderLayer): DecoderBottleneckLayer(\n",
       "        (weight_layer1): Sequential(\n",
       "          (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer2): Sequential(\n",
       "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer3): Sequential(\n",
       "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (03 EncoderLayer): DecoderBottleneckLayer(\n",
       "        (weight_layer1): Sequential(\n",
       "          (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer2): Sequential(\n",
       "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer3): Sequential(\n",
       "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (04 EncoderLayer): DecoderBottleneckLayer(\n",
       "        (weight_layer1): Sequential(\n",
       "          (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer2): Sequential(\n",
       "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer3): Sequential(\n",
       "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (05 EncoderLayer): DecoderBottleneckLayer(\n",
       "        (weight_layer1): Sequential(\n",
       "          (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer2): Sequential(\n",
       "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer3): Sequential(\n",
       "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): ConvTranspose2d(256, 512, kernel_size=(1, 1), stride=(2, 2), output_padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (upsample): Sequential(\n",
       "          (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): ConvTranspose2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), output_padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv3): DecoderBottleneckBlock(\n",
       "      (00 EncoderLayer): DecoderBottleneckLayer(\n",
       "        (weight_layer1): Sequential(\n",
       "          (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer2): Sequential(\n",
       "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer3): Sequential(\n",
       "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (01 EncoderLayer): DecoderBottleneckLayer(\n",
       "        (weight_layer1): Sequential(\n",
       "          (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer2): Sequential(\n",
       "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer3): Sequential(\n",
       "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (02 EncoderLayer): DecoderBottleneckLayer(\n",
       "        (weight_layer1): Sequential(\n",
       "          (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer2): Sequential(\n",
       "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer3): Sequential(\n",
       "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (03 EncoderLayer): DecoderBottleneckLayer(\n",
       "        (weight_layer1): Sequential(\n",
       "          (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer2): Sequential(\n",
       "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer3): Sequential(\n",
       "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): ConvTranspose2d(128, 256, kernel_size=(1, 1), stride=(2, 2), output_padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (upsample): Sequential(\n",
       "          (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): ConvTranspose2d(512, 256, kernel_size=(1, 1), stride=(2, 2), output_padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv4): DecoderBottleneckBlock(\n",
       "      (00 EncoderLayer): DecoderBottleneckLayer(\n",
       "        (weight_layer1): Sequential(\n",
       "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer2): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer3): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (01 EncoderLayer): DecoderBottleneckLayer(\n",
       "        (weight_layer1): Sequential(\n",
       "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer2): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer3): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (02 EncoderLayer): DecoderBottleneckLayer(\n",
       "        (weight_layer1): Sequential(\n",
       "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer2): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (weight_layer3): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): ConvTranspose2d(64, 64, kernel_size=(1, 1), stride=(2, 2), output_padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (upsample): Sequential(\n",
       "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): ConvTranspose2d(256, 64, kernel_size=(1, 1), stride=(2, 2), output_padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv5): Sequential(\n",
       "      (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): ConvTranspose2d(64, 3, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), output_padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (gate): Sigmoid()\n",
       "  )\n",
       "  (motor_decoder): LSTMCell(256, 512)\n",
       "  (lang_decoder): LSTMCell(256, 512)\n",
       "  (lang_head): Linear(in_features=512, out_features=65, bias=True)\n",
       "  (motor_cmd_head): Linear(in_features=512, out_features=65, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = JEPSAMDecoder(cfg=cfg)\n",
    "\n",
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6e35d65-745c-46aa-84e1-1014c3babf5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:16.471353Z",
     "iopub.status.busy": "2023-06-27T03:54:16.470997Z",
     "iopub.status.idle": "2023-06-27T03:54:16.501415Z",
     "shell.execute_reply": "2023-06-27T03:54:16.500638Z",
     "shell.execute_reply.started": "2023-06-27T03:54:16.471332Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(decoder.embedding.parameters()).is_cuda, decoder.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0155d83-00a7-43ea-999c-3e0a3aac7051",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Decoding language modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2cdc9b85-23ad-45d2-b942-3818da0279b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:16.502579Z",
     "iopub.status.busy": "2023-06-27T03:54:16.502315Z",
     "iopub.status.idle": "2023-06-27T03:54:16.639858Z",
     "shell.execute_reply": "2023-06-27T03:54:16.637713Z",
     "shell.execute_reply.started": "2023-06-27T03:54:16.502547Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 512]), torch.Size([2, 512]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh, cc = decoder._rearrange_states(h, c)\n",
    "hh.shape, cc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7df295ee-b6df-43f3-929a-bda5891e394d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:16.643469Z",
     "iopub.status.busy": "2023-06-27T03:54:16.642217Z",
     "iopub.status.idle": "2023-06-27T03:54:16.763975Z",
     "shell.execute_reply": "2023-06-27T03:54:16.762034Z",
     "shell.execute_reply.started": "2023-06-27T03:54:16.643397Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68804fba-6db3-4099-9ff1-95660df08e51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:16.767780Z",
     "iopub.status.busy": "2023-06-27T03:54:16.766917Z",
     "iopub.status.idle": "2023-06-27T03:54:16.850330Z",
     "shell.execute_reply": "2023-06-27T03:54:16.849773Z",
     "shell.execute_reply.started": "2023-06-27T03:54:16.767709Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "B, ML, NFTRS = o.shape\n",
    "\n",
    "ad_out = decoder._decode_action_description(\n",
    "    batch_size=B, \n",
    "    max_len=ML, \n",
    "    hidden=(hh, cc)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27738918-1195-4fdb-af7d-ea014e908b40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:16.851426Z",
     "iopub.status.busy": "2023-06-27T03:54:16.851215Z",
     "iopub.status.idle": "2023-06-27T03:54:16.984169Z",
     "shell.execute_reply": "2023-06-27T03:54:16.981889Z",
     "shell.execute_reply.started": "2023-06-27T03:54:16.851406Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmd_out = decoder._decode_motor_command(\n",
    "    batch_size=B, \n",
    "    max_len=ML, \n",
    "    hidden=(hh, cc)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb853a0a-a460-4ac5-a3ee-346324a9f89e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:16.987358Z",
     "iopub.status.busy": "2023-06-27T03:54:16.986487Z",
     "iopub.status.idle": "2023-06-27T03:54:17.066215Z",
     "shell.execute_reply": "2023-06-27T03:54:17.065527Z",
     "shell.execute_reply.started": "2023-06-27T03:54:16.987282Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 11, 65]), torch.Size([2, 11, 65]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd_out.shape, ad_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77b9ac2b-5c0f-4f64-8e3d-2c0313160535",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:17.067537Z",
     "iopub.status.busy": "2023-06-27T03:54:17.066981Z",
     "iopub.status.idle": "2023-06-27T03:54:17.221077Z",
     "shell.execute_reply": "2023-06-27T03:54:17.218703Z",
     "shell.execute_reply.started": "2023-06-27T03:54:17.067515Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7, 33, 62, 17, 59, 54, 17, 11, 42, 55, 26], device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd_out.argmax(dim=-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19c1c979-6080-4567-9339-02a294ec0f6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:17.225185Z",
     "iopub.status.busy": "2023-06-27T03:54:17.223947Z",
     "iopub.status.idle": "2023-06-27T03:54:17.291316Z",
     "shell.execute_reply": "2023-06-27T03:54:17.290655Z",
     "shell.execute_reply.started": "2023-06-27T03:54:17.225105Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoded_ad = decoder.pred_to_str(ad_out)\n",
    "decoded_cmd = decoder.pred_to_str(cmd_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "804982f5-f7c3-440d-b19c-2c5884d6dd4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:17.292219Z",
     "iopub.status.busy": "2023-06-27T03:54:17.292012Z",
     "iopub.status.idle": "2023-06-27T03:54:17.431603Z",
     "shell.execute_reply": "2023-06-27T03:54:17.429452Z",
     "shell.execute_reply.started": "2023-06-27T03:54:17.292200Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['top',\n",
       " 'top',\n",
       " 'top',\n",
       " 'top',\n",
       " 'top',\n",
       " 'top',\n",
       " 'left',\n",
       " '[PAD]',\n",
       " 'top',\n",
       " 'top',\n",
       " 'top']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_ad[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "053273bd-202b-4b4a-b042-a3003d28fff6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:17.435050Z",
     "iopub.status.busy": "2023-06-27T03:54:17.434257Z",
     "iopub.status.idle": "2023-06-27T03:54:17.507979Z",
     "shell.execute_reply": "2023-06-27T03:54:17.507327Z",
     "shell.execute_reply.started": "2023-06-27T03:54:17.434980Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[':BREAKFAST-CEREAL',\n",
       " 'POSE-12',\n",
       " 'the',\n",
       " ':MILK',\n",
       " 'put',\n",
       " 'in',\n",
       " ':MILK',\n",
       " ':CUBE',\n",
       " 'POSE-7',\n",
       " 'left',\n",
       " ':WEISSWURST']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_cmd[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da238f71-ee3c-4686-8e8b-7d84e084768e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Decoding visual modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec4d1fb5-6c54-42a9-bfe9-1f85e547cc18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:17.509107Z",
     "iopub.status.busy": "2023-06-27T03:54:17.508803Z",
     "iopub.status.idle": "2023-06-27T03:54:17.660695Z",
     "shell.execute_reply": "2023-06-27T03:54:17.659663Z",
     "shell.execute_reply.started": "2023-06-27T03:54:17.509082Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# img_ftrs = encoder.image_feature_extractor(data[0])\n",
    "# img_ftrs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5e1b666-613b-4a2c-a4ff-62f66a4f1221",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:17.662131Z",
     "iopub.status.busy": "2023-06-27T03:54:17.661794Z",
     "iopub.status.idle": "2023-06-27T03:54:17.785045Z",
     "shell.execute_reply": "2023-06-27T03:54:17.782859Z",
     "shell.execute_reply.started": "2023-06-27T03:54:17.662099Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rec_img = decoder._reconstruct_image(img_ftrs.cuda())\n",
    "\n",
    "# rec_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82232728-fe58-4401-b4b2-95299905f7ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4d5a094-5528-460e-873e-61d2acc8a691",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T02:20:48.761277Z",
     "iopub.status.busy": "2023-06-27T02:20:48.760533Z",
     "iopub.status.idle": "2023-06-27T02:20:48.800505Z",
     "shell.execute_reply": "2023-06-27T02:20:48.799796Z",
     "shell.execute_reply.started": "2023-06-27T02:20:48.761208Z"
    },
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Decoder I/O "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e2172a4-d845-412c-b747-135ca24e221d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:17.788347Z",
     "iopub.status.busy": "2023-06-27T03:54:17.787638Z",
     "iopub.status.idle": "2023-06-27T03:54:17.987417Z",
     "shell.execute_reply": "2023-06-27T03:54:17.986636Z",
     "shell.execute_reply.started": "2023-06-27T03:54:17.788281Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "per_image_rec, goal_image, lang_out, motor_out = decoder(\n",
    "    enc_output=o, \n",
    "    len_enc_output=lo, \n",
    "    hidden=h, \n",
    "    carousel=c\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0994c084-0aab-4e04-b82f-6cc052cdce8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:17.988347Z",
     "iopub.status.busy": "2023-06-27T03:54:17.988132Z",
     "iopub.status.idle": "2023-06-27T03:54:18.019869Z",
     "shell.execute_reply": "2023-06-27T03:54:18.019256Z",
     "shell.execute_reply.started": "2023-06-27T03:54:17.988326Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 224, 224]),\n",
       " torch.Size([2, 3, 224, 224]),\n",
       " torch.Size([2, 11, 65]),\n",
       " torch.Size([2, 11, 65]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_image_rec.shape, goal_image.shape, lang_out.shape, motor_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cbb999-8a27-4675-a09d-dd0e57366a02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7c98918-a0fa-4899-a6c9-58c40e14cdd8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### AE: JEPSAM\n",
    "    - Enc: JEPSAMEncoder\n",
    "    - Dec: JEPSAMDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "835a6e30-c0cc-49f9-99fc-3f548461c91b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:18.020916Z",
     "iopub.status.busy": "2023-06-27T03:54:18.020695Z",
     "iopub.status.idle": "2023-06-27T03:54:18.162531Z",
     "shell.execute_reply": "2023-06-27T03:54:18.160287Z",
     "shell.execute_reply.started": "2023-06-27T03:54:18.020895Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class JEPSAM(nn.Module):\n",
    "    \"\"\"\n",
    "    This class is an Autoencoder based deep learning implementation of a Joint Episdoic, Procedural, and Semantic Memory.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, cfg: Dict):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        # encoder\n",
    "        self.encoder = JEPSAMEncoder(cfg=self.cfg)\n",
    "        # decoder\n",
    "        self.decoder = JEPSAMDecoder(cfg=self.cfg)\n",
    "        # weight tying\n",
    "        self.decoder.embedding.weight = self.encoder.embedding.weight\n",
    "        \n",
    "        self.device = self.cfg.TRAIN.GPU_DEVICE if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        \n",
    "    def forward(\n",
    "        self, \n",
    "        inp, \n",
    "        mode:str=\"train\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        \n",
    "        # encode\n",
    "        o, lo, h, c  = self.encoder(inp)\n",
    "        \n",
    "        # decode\n",
    "        reconstructed_image, goal_image, decoded_action_desc, decoded_cmd = self.decoder(\n",
    "            enc_output=o, \n",
    "            len_enc_output=lo, \n",
    "            hidden=h, \n",
    "            carousel=c\n",
    "        )\n",
    "\n",
    "        return reconstructed_image, goal_image, decoded_action_desc, decoded_cmd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "29defbab-27f7-4374-93a8-e60d8fdca6f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:18.166743Z",
     "iopub.status.busy": "2023-06-27T03:54:18.165959Z",
     "iopub.status.idle": "2023-06-27T03:54:19.103219Z",
     "shell.execute_reply": "2023-06-27T03:54:19.102440Z",
     "shell.execute_reply.started": "2023-06-27T03:54:18.166675Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JEPSAM(\n",
       "  (encoder): JEPSAMEncoder(\n",
       "    (embedding): Embedding(65, 256)\n",
       "    (image_feature_extractor): Sequential(\n",
       "      (0): ResNetEncoder(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): EncoderBottleneckBlock(\n",
       "          (00 MaxPooling): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          (01 EncoderLayer): EncoderBottleneckLayer(\n",
       "            (weight_layer1): Sequential(\n",
       "              (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer2): Sequential(\n",
       "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer3): Sequential(\n",
       "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (up_scale): Sequential(\n",
       "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (relu): Sequential(\n",
       "              (0): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (02 EncoderLayer): EncoderBottleneckLayer(\n",
       "            (weight_layer1): Sequential(\n",
       "              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer2): Sequential(\n",
       "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer3): Sequential(\n",
       "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (relu): Sequential(\n",
       "              (0): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (03 EncoderLayer): EncoderBottleneckLayer(\n",
       "            (weight_layer1): Sequential(\n",
       "              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer2): Sequential(\n",
       "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer3): Sequential(\n",
       "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (relu): Sequential(\n",
       "              (0): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (conv3): EncoderBottleneckBlock(\n",
       "          (00 EncoderLayer): EncoderBottleneckLayer(\n",
       "            (weight_layer1): Sequential(\n",
       "              (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer2): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer3): Sequential(\n",
       "              (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (relu): Sequential(\n",
       "              (0): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (01 EncoderLayer): EncoderBottleneckLayer(\n",
       "            (weight_layer1): Sequential(\n",
       "              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer2): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer3): Sequential(\n",
       "              (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (relu): Sequential(\n",
       "              (0): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (02 EncoderLayer): EncoderBottleneckLayer(\n",
       "            (weight_layer1): Sequential(\n",
       "              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer2): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer3): Sequential(\n",
       "              (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (relu): Sequential(\n",
       "              (0): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (03 EncoderLayer): EncoderBottleneckLayer(\n",
       "            (weight_layer1): Sequential(\n",
       "              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer2): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer3): Sequential(\n",
       "              (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (relu): Sequential(\n",
       "              (0): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (conv4): EncoderBottleneckBlock(\n",
       "          (00 EncoderLayer): EncoderBottleneckLayer(\n",
       "            (weight_layer1): Sequential(\n",
       "              (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer2): Sequential(\n",
       "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer3): Sequential(\n",
       "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (relu): Sequential(\n",
       "              (0): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (01 EncoderLayer): EncoderBottleneckLayer(\n",
       "            (weight_layer1): Sequential(\n",
       "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer2): Sequential(\n",
       "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer3): Sequential(\n",
       "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (relu): Sequential(\n",
       "              (0): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (02 EncoderLayer): EncoderBottleneckLayer(\n",
       "            (weight_layer1): Sequential(\n",
       "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer2): Sequential(\n",
       "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer3): Sequential(\n",
       "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (relu): Sequential(\n",
       "              (0): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (03 EncoderLayer): EncoderBottleneckLayer(\n",
       "            (weight_layer1): Sequential(\n",
       "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer2): Sequential(\n",
       "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer3): Sequential(\n",
       "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (relu): Sequential(\n",
       "              (0): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (04 EncoderLayer): EncoderBottleneckLayer(\n",
       "            (weight_layer1): Sequential(\n",
       "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer2): Sequential(\n",
       "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer3): Sequential(\n",
       "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (relu): Sequential(\n",
       "              (0): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (05 EncoderLayer): EncoderBottleneckLayer(\n",
       "            (weight_layer1): Sequential(\n",
       "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer2): Sequential(\n",
       "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer3): Sequential(\n",
       "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (relu): Sequential(\n",
       "              (0): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (conv5): EncoderBottleneckBlock(\n",
       "          (00 EncoderLayer): EncoderBottleneckLayer(\n",
       "            (weight_layer1): Sequential(\n",
       "              (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer2): Sequential(\n",
       "              (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer3): Sequential(\n",
       "              (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (relu): Sequential(\n",
       "              (0): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (01 EncoderLayer): EncoderBottleneckLayer(\n",
       "            (weight_layer1): Sequential(\n",
       "              (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer2): Sequential(\n",
       "              (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer3): Sequential(\n",
       "              (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (relu): Sequential(\n",
       "              (0): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (02 EncoderLayer): EncoderBottleneckLayer(\n",
       "            (weight_layer1): Sequential(\n",
       "              (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer2): Sequential(\n",
       "              (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (weight_layer3): Sequential(\n",
       "              (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (relu): Sequential(\n",
       "              (0): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Flatten(start_dim=1, end_dim=-1)\n",
       "      (2): Linear(in_features=100352, out_features=256, bias=True)\n",
       "    )\n",
       "    (feature_mixing): LSTM(256, 256, num_layers=2, dropout=0.35, bidirectional=True)\n",
       "  )\n",
       "  (decoder): JEPSAMDecoder(\n",
       "    (embedding): Embedding(65, 256)\n",
       "    (img_projection): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=256, out_features=100352, bias=True)\n",
       "    )\n",
       "    (img_decoder): ResNetDecoder(\n",
       "      (conv1): DecoderBottleneckBlock(\n",
       "        (00 EncoderLayer): DecoderBottleneckLayer(\n",
       "          (weight_layer1): Sequential(\n",
       "            (0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer2): Sequential(\n",
       "            (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer3): Sequential(\n",
       "            (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (01 EncoderLayer): DecoderBottleneckLayer(\n",
       "          (weight_layer1): Sequential(\n",
       "            (0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer2): Sequential(\n",
       "            (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer3): Sequential(\n",
       "            (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (02 EncoderLayer): DecoderBottleneckLayer(\n",
       "          (weight_layer1): Sequential(\n",
       "            (0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer2): Sequential(\n",
       "            (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer3): Sequential(\n",
       "            (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): ConvTranspose2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), output_padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (upsample): Sequential(\n",
       "            (0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): ConvTranspose2d(2048, 1024, kernel_size=(1, 1), stride=(2, 2), output_padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (conv2): DecoderBottleneckBlock(\n",
       "        (00 EncoderLayer): DecoderBottleneckLayer(\n",
       "          (weight_layer1): Sequential(\n",
       "            (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer2): Sequential(\n",
       "            (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer3): Sequential(\n",
       "            (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (01 EncoderLayer): DecoderBottleneckLayer(\n",
       "          (weight_layer1): Sequential(\n",
       "            (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer2): Sequential(\n",
       "            (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer3): Sequential(\n",
       "            (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (02 EncoderLayer): DecoderBottleneckLayer(\n",
       "          (weight_layer1): Sequential(\n",
       "            (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer2): Sequential(\n",
       "            (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer3): Sequential(\n",
       "            (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (03 EncoderLayer): DecoderBottleneckLayer(\n",
       "          (weight_layer1): Sequential(\n",
       "            (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer2): Sequential(\n",
       "            (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer3): Sequential(\n",
       "            (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (04 EncoderLayer): DecoderBottleneckLayer(\n",
       "          (weight_layer1): Sequential(\n",
       "            (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer2): Sequential(\n",
       "            (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer3): Sequential(\n",
       "            (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (05 EncoderLayer): DecoderBottleneckLayer(\n",
       "          (weight_layer1): Sequential(\n",
       "            (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer2): Sequential(\n",
       "            (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer3): Sequential(\n",
       "            (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): ConvTranspose2d(256, 512, kernel_size=(1, 1), stride=(2, 2), output_padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (upsample): Sequential(\n",
       "            (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): ConvTranspose2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), output_padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (conv3): DecoderBottleneckBlock(\n",
       "        (00 EncoderLayer): DecoderBottleneckLayer(\n",
       "          (weight_layer1): Sequential(\n",
       "            (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer2): Sequential(\n",
       "            (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer3): Sequential(\n",
       "            (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (01 EncoderLayer): DecoderBottleneckLayer(\n",
       "          (weight_layer1): Sequential(\n",
       "            (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer2): Sequential(\n",
       "            (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer3): Sequential(\n",
       "            (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (02 EncoderLayer): DecoderBottleneckLayer(\n",
       "          (weight_layer1): Sequential(\n",
       "            (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer2): Sequential(\n",
       "            (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer3): Sequential(\n",
       "            (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (03 EncoderLayer): DecoderBottleneckLayer(\n",
       "          (weight_layer1): Sequential(\n",
       "            (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer2): Sequential(\n",
       "            (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer3): Sequential(\n",
       "            (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): ConvTranspose2d(128, 256, kernel_size=(1, 1), stride=(2, 2), output_padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (upsample): Sequential(\n",
       "            (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): ConvTranspose2d(512, 256, kernel_size=(1, 1), stride=(2, 2), output_padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (conv4): DecoderBottleneckBlock(\n",
       "        (00 EncoderLayer): DecoderBottleneckLayer(\n",
       "          (weight_layer1): Sequential(\n",
       "            (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer2): Sequential(\n",
       "            (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer3): Sequential(\n",
       "            (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (01 EncoderLayer): DecoderBottleneckLayer(\n",
       "          (weight_layer1): Sequential(\n",
       "            (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer2): Sequential(\n",
       "            (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer3): Sequential(\n",
       "            (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (02 EncoderLayer): DecoderBottleneckLayer(\n",
       "          (weight_layer1): Sequential(\n",
       "            (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer2): Sequential(\n",
       "            (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (weight_layer3): Sequential(\n",
       "            (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): ConvTranspose2d(64, 64, kernel_size=(1, 1), stride=(2, 2), output_padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (upsample): Sequential(\n",
       "            (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): ConvTranspose2d(256, 64, kernel_size=(1, 1), stride=(2, 2), output_padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (conv5): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): ConvTranspose2d(64, 3, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), output_padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (gate): Sigmoid()\n",
       "    )\n",
       "    (motor_decoder): LSTMCell(256, 512)\n",
       "    (lang_decoder): LSTMCell(256, 512)\n",
       "    (lang_head): Linear(in_features=512, out_features=65, bias=True)\n",
       "    (motor_cmd_head): Linear(in_features=512, out_features=65, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jepsam = JEPSAM(cfg=cfg).cuda()\n",
    "\n",
    "jepsam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de30da4-4ba8-48c2-8a44-02087f1bee1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T04:30:04.913793Z",
     "iopub.status.busy": "2023-06-25T04:30:04.913540Z",
     "iopub.status.idle": "2023-06-25T04:30:04.947047Z",
     "shell.execute_reply": "2023-06-25T04:30:04.946238Z",
     "shell.execute_reply.started": "2023-06-25T04:30:04.913772Z"
    },
    "tags": []
   },
   "source": [
    "#### JEPSAM I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "685388a6-cf28-4bc4-99cb-922bc75726c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:19.107463Z",
     "iopub.status.busy": "2023-06-27T03:54:19.107139Z",
     "iopub.status.idle": "2023-06-27T03:54:19.214227Z",
     "shell.execute_reply": "2023-06-27T03:54:19.213625Z",
     "shell.execute_reply.started": "2023-06-27T03:54:19.107442Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "per_image_rec, goal_image, lang_out, motor_out = jepsam(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31782208-04d6-45c0-9270-60de1f9bd33a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:54:19.215643Z",
     "iopub.status.busy": "2023-06-27T03:54:19.215413Z",
     "iopub.status.idle": "2023-06-27T03:54:19.242637Z",
     "shell.execute_reply": "2023-06-27T03:54:19.241938Z",
     "shell.execute_reply.started": "2023-06-27T03:54:19.215622Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 224, 224]),\n",
       " torch.Size([2, 3, 224, 224]),\n",
       " torch.Size([2, 11, 65]),\n",
       " torch.Size([2, 11, 65]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_image_rec.shape, goal_image.shape, lang_out.shape, motor_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "61667a1a-d486-483d-b593-0f55f4383b85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:55:30.101900Z",
     "iopub.status.busy": "2023-06-27T03:55:30.101321Z",
     "iopub.status.idle": "2023-06-27T03:55:30.149473Z",
     "shell.execute_reply": "2023-06-27T03:55:30.148416Z",
     "shell.execute_reply.started": "2023-06-27T03:55:30.101849Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[51, 56, 34, 42, 60, 33, 38,  4,  4, 30, 35],\n",
       "        [48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48]], device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motor_out.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "df7245e4-be43-4b02-adbb-a69763f6916f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:58:30.035498Z",
     "iopub.status.busy": "2023-06-27T03:58:30.035050Z",
     "iopub.status.idle": "2023-06-27T03:58:30.072705Z",
     "shell.execute_reply": "2023-06-27T03:58:30.071930Z",
     "shell.execute_reply.started": "2023-06-27T03:58:30.035457Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(607.4091, device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.mse_loss(motor_out.float().argmax(dim=-1), cmd.squeeze(1).float().cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4adbaa46-cd52-4c17-8849-2109ebb03191",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T03:58:12.175253Z",
     "iopub.status.busy": "2023-06-27T03:58:12.174902Z",
     "iopub.status.idle": "2023-06-27T03:58:12.213737Z",
     "shell.execute_reply": "2023-06-27T03:58:12.212982Z",
     "shell.execute_reply.started": "2023-06-27T03:58:12.175221Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 11]), torch.Size([2, 11]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd.shape, motor_out.argmax(dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f8e7f8-63dc-4f9f-8a2e-95d246af1f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
