{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d561bf6-b777-4f72-8632-d0ee7ab53273",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T04:48:58.299687Z",
     "iopub.status.busy": "2023-06-22T04:48:58.299389Z",
     "iopub.status.idle": "2023-06-22T04:48:58.529033Z",
     "shell.execute_reply": "2023-06-22T04:48:58.527863Z",
     "shell.execute_reply.started": "2023-06-22T04:48:58.299659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 22 06:48:58 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   67C    P0    25W /  N/A |    531MiB /  6069MiB |      4%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1366      G   /usr/lib/xorg/Xorg                 53MiB |\n",
      "|    0   N/A  N/A      5264      G   /usr/lib/xorg/Xorg                206MiB |\n",
      "|    0   N/A  N/A      5541      G   /usr/bin/gnome-shell               69MiB |\n",
      "|    0   N/A  N/A      6029      G   /opt/freedownloadmanager/fdm        1MiB |\n",
      "|    0   N/A  N/A     10606      G   ...RendererForSitePerProcess        8MiB |\n",
      "|    0   N/A  N/A     12775      G   ...456187822775190002,131072      128MiB |\n",
      "|    0   N/A  N/A     87610      G   ...RendererForSitePerProcess       50MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ed9ac595-8c04-4dd1-bb57-a847b372bcc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T05:35:39.118138Z",
     "iopub.status.busy": "2023-06-22T05:35:39.117881Z",
     "iopub.status.idle": "2023-06-22T05:35:39.155068Z",
     "shell.execute_reply": "2023-06-22T05:35:39.154061Z",
     "shell.execute_reply.started": "2023-06-22T05:35:39.118116Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from addict import Dict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "import torchvision.models as torchvision_models\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "import IPython\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1be02207-6411-467c-b8c1-7c49d94269ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T04:48:56.096777Z",
     "iopub.status.busy": "2023-06-22T04:48:56.096509Z",
     "iopub.status.idle": "2023-06-22T04:48:58.298125Z",
     "shell.execute_reply": "2023-06-22T04:48:58.297166Z",
     "shell.execute_reply.started": "2023-06-22T04:48:56.096756Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import models\n",
    "from utils.parser import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8530e2bd-2a8a-4a73-8060-eff13096f5eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T05:43:23.667320Z",
     "iopub.status.busy": "2023-06-22T05:43:23.666520Z",
     "iopub.status.idle": "2023-06-22T05:43:23.753356Z",
     "shell.execute_reply": "2023-06-22T05:43:23.751282Z",
     "shell.execute_reply.started": "2023-06-22T05:43:23.667252Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg = load_config(config_file_path=\"../configs/aejeps_cfg.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c82e46d7-9cdb-4a64-a6a3-b715f1ce2fcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T05:43:23.888872Z",
     "iopub.status.busy": "2023-06-22T05:43:23.888086Z",
     "iopub.status.idle": "2023-06-22T05:43:23.995256Z",
     "shell.execute_reply": "2023-06-22T05:43:23.990022Z",
     "shell.execute_reply.started": "2023-06-22T05:43:23.888803Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EMBEDDING_DIM': 128,\n",
       " 'HIDDEN_DIM': 512,\n",
       " 'NUM_LAYERS_ENCODER': 2,\n",
       " 'BATCH_FIRST': True,\n",
       " 'ENCODER_DROPOUT': 0.35,\n",
       " 'IS_BIDIRECTIONAL': True,\n",
       " 'NUM_LAYERS_MOTOR': 1,\n",
       " 'ACTIVATION_MOTOR': 'Gelu',\n",
       " 'MOTOR_DROPOUT': 0.2,\n",
       " 'NUM_LAYERS_LANG': 2,\n",
       " 'ACTIVATION_LANG': 'Gelu',\n",
       " 'LANG_DROPOUT': 0.2}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.AEJEPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2101500-0b1e-4358-9beb-55816a766de4",
   "metadata": {},
   "source": [
    "## Model refectoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13480e66-708a-418a-84c3-9529d9398d00",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b847ce-3279-4fc7-9fa5-2137794772ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### CNN backbone builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "21746089-b99a-4b32-9cac-6b7336f1e468",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T05:25:28.837746Z",
     "iopub.status.busy": "2023-06-22T05:25:28.837000Z",
     "iopub.status.idle": "2023-06-22T05:25:28.916545Z",
     "shell.execute_reply": "2023-06-22T05:25:28.914382Z",
     "shell.execute_reply.started": "2023-06-22T05:25:28.837679Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cnn_backbone(\n",
    "    cfg:Dict, \n",
    "    backbone_name:str=\"resnet50\", \n",
    "    freeze:bool=True,\n",
    "    fc_out:int=None\n",
    "):\n",
    "    backbone = getattr(torchvision_models, backbone_name)(weights=cfg.MODEL.CNN_BACKBONES[backbone_name])\n",
    "    \n",
    "    # freeze backbone if specified\n",
    "    if freeze:\n",
    "        for param in backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    if fc_out is not None:\n",
    "        # resnet-based models\n",
    "        if \"resnet\" in backbone_name.lower():\n",
    "            backbone.fc = nn.Linear(in_features=backbone.fc.in_features, out_features=fc_out)\n",
    "            \n",
    "    return backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e0d6e9c9-89e0-404f-8d7c-b01a15ce79bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T05:25:29.428634Z",
     "iopub.status.busy": "2023-06-22T05:25:29.427948Z",
     "iopub.status.idle": "2023-06-22T05:25:29.865668Z",
     "shell.execute_reply": "2023-06-22T05:25:29.864898Z",
     "shell.execute_reply.started": "2023-06-22T05:25:29.428585Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=512, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = get_cnn_backbone(cfg=cfg, fc_out=512)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d32eadb-4f4d-49e6-8716-f45b406a9d49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a8897e77-75e0-4236-8fe8-133b5553a0fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T05:26:53.503545Z",
     "iopub.status.busy": "2023-06-22T05:26:53.503182Z",
     "iopub.status.idle": "2023-06-22T05:26:53.525302Z",
     "shell.execute_reply": "2023-06-22T05:26:53.524656Z",
     "shell.execute_reply.started": "2023-06-22T05:26:53.503522Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = torch.randn((1, 3, 224, 224))\n",
    "\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "46cc321f-8bd9-44ff-b694-5ab30bf9181c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T05:26:54.266907Z",
     "iopub.status.busy": "2023-06-22T05:26:54.266050Z",
     "iopub.status.idle": "2023-06-22T05:26:54.665006Z",
     "shell.execute_reply": "2023-06-22T05:26:54.664300Z",
     "shell.execute_reply.started": "2023-06-22T05:26:54.266838Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = b(xx)\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668289b9-8275-4e83-ab17-0790d843aa9e",
   "metadata": {},
   "source": [
    "#### JEPSAM encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "15c0e95f-9b52-4d8d-ac2b-673020ebbd16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T05:54:34.048736Z",
     "iopub.status.busy": "2023-06-22T05:54:34.046410Z",
     "iopub.status.idle": "2023-06-22T05:54:34.082113Z",
     "shell.execute_reply": "2023-06-22T05:54:34.081324Z",
     "shell.execute_reply.started": "2023-06-22T05:54:34.048645Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class JEPSAMEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        cfg: Dict, \n",
    "        cnn_backbone_name:str=\"resnet50\", \n",
    "        cnn_fc_out:int=512\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(cfg.DATASET.VOCABULARY_SIZE, cfg.AEJEPS.EMBEDDING_DIM)\n",
    "        \n",
    "        self.image_feature_extractor = get_cnn_backbone(\n",
    "            cfg=cfg,\n",
    "            backbone_name=cnn_backbone_name,\n",
    "            fc_out=cnn_fc_out\n",
    "        )\n",
    "        \n",
    "        # features mixer\n",
    "        encoder_input_dim = cfg.AEJEPS.EMBEDDING_DIM + 2 * self.image_feature_extractor.fc.in_features + cfg.DATASET.NUM_COMMANDS\n",
    "\n",
    "        \n",
    "        self.feature_mixing = nn.LSTM(\n",
    "            input_size=encoder_input_dim, \n",
    "            hidden_size=cfg.AEJEPS.HIDDEN_DIM, \n",
    "            num_layers=cfg.AEJEPS.NUM_LAYERS_ENCODER,\n",
    "            dropout=cfg.AEJEPS.ENCODER_DROPOUT, \n",
    "            bidirectional=cfg.AEJEPS.IS_BIDIRECTIONAL\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, inp:dict, mode:str='train'):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        B, max_len, *_ = inp[\"action_desc\"].shape\n",
    "\n",
    "        # 1. Image feature extraction\n",
    "        feats_per = self.image_feature_extractor(inp[\"in_state\"])\n",
    "        feats_goal = self.image_feature_extractor(inp[\"goal_state\"])\n",
    "        ## Batch size x feat_dim -> Batch_size x (max_len x feat_dim) -> Batch_size x max_len x feat_dim\n",
    "        feats_per = feats_per.repeat((1, max_len)).reshape((B, max_len, -1))\n",
    "        feats_goal = feats_goal.repeat((1, max_len)).reshape((B, max_len, -1))\n",
    "        \n",
    "        # 2. Text feature extraction\n",
    "        print(inp[\"action_desc\"][\"ids\"])\n",
    "        action_desc_emb = self.embedding(inp[\"action_desc\"][\"ids\"])\n",
    "        motor_cmd_emb = self.embedding(inp[\"motor_cmd\"][\"ids\"])\n",
    "        # For each batch entry determine the length of the longest of the text sequence\n",
    "        lengths_max = [max(ltext, lcmd)\n",
    "                       for ltext, lcmd in zip(inp[\"action_desc\"][\"length\"], inp[\"motor_cmd\"][\"length\"])]\n",
    "        \n",
    "        # 3. Feature Fusion\n",
    "        concat_feats = torch.cat((feats_per, feats_goal, action_desc_emb, motor_cmd_emb), dim=2)\n",
    "        \n",
    "        # 4. Feature mixing\n",
    "        packed_input = pack_padded_sequence(input=concat_feats, lengths=lengths_max, enforce_sorted=False)\n",
    "        \n",
    "        output, (hidden, carousel) = self.feature_mixing(packed_input)\n",
    "        \n",
    "        return output, (hidden, carousel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "51cfedb8-0dfb-4ceb-a39e-3b271039247a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T05:54:34.815034Z",
     "iopub.status.busy": "2023-06-22T05:54:34.814163Z",
     "iopub.status.idle": "2023-06-22T05:54:35.378566Z",
     "shell.execute_reply": "2023-06-22T05:54:35.377805Z",
     "shell.execute_reply.started": "2023-06-22T05:54:34.814958Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = JEPSAMEncoder(cfg=cfg)\n",
    "\n",
    "# encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "186cab93-1ea5-401c-ad0c-27fcfb4dd441",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T05:54:36.922793Z",
     "iopub.status.busy": "2023-06-22T05:54:36.922019Z",
     "iopub.status.idle": "2023-06-22T05:54:37.188468Z",
     "shell.execute_reply": "2023-06-22T05:54:37.187493Z",
     "shell.execute_reply.started": "2023-06-22T05:54:36.922725Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new(): invalid data type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [88]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m iinp \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min_state\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mrandn((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)),\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoal_state\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mrandn((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)),\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction_desc\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mrandn((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m64\u001b[39m)),\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmotor_cmd\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mrandn((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m128\u001b[39m))\n\u001b[1;32m      6\u001b[0m }\n\u001b[0;32m----> 7\u001b[0m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43miinp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jeps/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [86]\u001b[0m, in \u001b[0;36mJEPSAMEncoder.forward\u001b[0;34m(self, inp, mode)\u001b[0m\n\u001b[1;32m     42\u001b[0m feats_goal \u001b[38;5;241m=\u001b[39m feats_goal\u001b[38;5;241m.\u001b[39mrepeat((\u001b[38;5;241m1\u001b[39m, max_len))\u001b[38;5;241m.\u001b[39mreshape((B, max_len, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# 2. Text feature extraction\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43minp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maction_desc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     46\u001b[0m action_desc_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(inp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction_desc\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     47\u001b[0m motor_cmd_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(inp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmotor_cmd\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: new(): invalid data type 'str'"
     ]
    }
   ],
   "source": [
    "iinp = {\n",
    "        \"in_state\": torch.randn((1, 3, 224, 224)),\n",
    "        \"goal_state\": torch.randn((1, 3, 224, 224)),\n",
    "        \"action_desc\": {\n",
    "            torch.randn((1, 1, 64))\n",
    "        },\n",
    "        \"motor_cmd\": torch.randn((1, 1, 128))\n",
    "}\n",
    "encoder(iinp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6fcb3238-db0e-4eef-9f22-6390f25c28f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T05:51:26.889625Z",
     "iopub.status.busy": "2023-06-22T05:51:26.888940Z",
     "iopub.status.idle": "2023-06-22T05:51:26.963841Z",
     "shell.execute_reply": "2023-06-22T05:51:26.962595Z",
     "shell.execute_reply.started": "2023-06-22T05:51:26.889572Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [76]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jeps/lib/python3.8/site-packages/torchinfo/torchinfo.py:220\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(device)\n\u001b[1;32m    216\u001b[0m validate_user_params(\n\u001b[1;32m    217\u001b[0m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001b[1;32m    218\u001b[0m )\n\u001b[0;32m--> 220\u001b[0m x, correct_input_size \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_input\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m summary_list \u001b[38;5;241m=\u001b[39m forward_pass(\n\u001b[1;32m    224\u001b[0m     model, x, batch_dim, cache_forward_pass, device, model_mode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    225\u001b[0m )\n\u001b[1;32m    226\u001b[0m formatting \u001b[38;5;241m=\u001b[39m FormattingOptions(depth, verbose, columns, col_width, rows)\n",
      "File \u001b[0;32m~/miniconda3/envs/jeps/lib/python3.8/site-packages/torchinfo/torchinfo.py:255\u001b[0m, in \u001b[0;36mprocess_input\u001b[0;34m(input_data, input_size, batch_dim, device, dtypes)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtypes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m         dtypes \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mfloat] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(input_size)\n\u001b[0;32m--> 255\u001b[0m     correct_input_size \u001b[38;5;241m=\u001b[39m \u001b[43mget_correct_input_sizes\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m     x \u001b[38;5;241m=\u001b[39m get_input_tensor(correct_input_size, batch_dim, dtypes, device)\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, correct_input_size\n",
      "File \u001b[0;32m~/miniconda3/envs/jeps/lib/python3.8/site-packages/torchinfo/torchinfo.py:556\u001b[0m, in \u001b[0;36mget_correct_input_sizes\u001b[0;34m(input_size)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(input_size, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    552\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput_size is not a recognized type. Please ensure input_size is valid.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    553\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor multiple inputs to the network, ensure input_size is a list of tuple \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    554\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msizes. If you are having trouble here, please submit a GitHub issue.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    555\u001b[0m     )\n\u001b[0;32m--> 556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m input_size \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;43many\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput_data is invalid, or negative size found in input_data.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(input_size, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(input_size[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mint\u001b[39m):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "summary(\n",
    "    encoder,\n",
    "    [\n",
    "        torch.randn((1, 3, 224, 224)),\n",
    "        torch.randn((1, 3, 224, 224)),\n",
    "        torch.randn((1, 1, 64)),\n",
    "        torch.randn((1, 1, 128))\n",
    "    ],\n",
    "    \n",
    "    dtypes=[\n",
    "        torch.float,\n",
    "        torch.float,\n",
    "        torch.long,\n",
    "        torch.long,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076388b3-b5d6-4f48-bfe9-bb85d67ff257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5016b85-5211-45b1-8a31-174e8bae82fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4917a5c8-01f8-4a97-b70f-a7177c7c5a5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, embedding_dim:):\n",
    "        \n",
    "        decoder_hidden_dim = self.num_directions * hidden_dim\n",
    "        \n",
    "        # motor command decoding layer\n",
    "        self.motor_decoder = nn.LSTMCell(\n",
    "            input_size=motor_dim, \n",
    "            hidden_size=decoder_hidden_dim, \n",
    "            num_layers=cfg.AEJEPS.NUM_LAYERS_MOTOR\n",
    "        )\n",
    "        # action desc. decoding layer\n",
    "        self.lang_decoder = nn.LSTMCell(\n",
    "            input_size=embedding_dim, \n",
    "            hidden_size=decoder_hidden_dim, \n",
    "            num_layers=num_layers_lang\n",
    "        )\n",
    "        \n",
    "        # projection layers\n",
    "        self.hidden_to_conv_in = nn.Linear(decoder_hidden_dim, 1024)\n",
    "        self.lang_head = nn.Linear(\n",
    "            in_features=decoder_hidden_dim, \n",
    "            out_features=vocabulary_size # To be discussed\n",
    "        )\n",
    "        self.motor_cmd_head = nn.Linear(\n",
    "            in_features=decoder_hidden_dim, \n",
    "            out_features=vocabulary_size # To be discussed\n",
    "        )\n",
    "\n",
    "        self.hidden2img = self.__get_transposed_convs(\n",
    "            decoder_hidden_dim, \n",
    "            image_size\n",
    "        )\n",
    "    \n",
    "    def forward(self):\n",
    "        pass\n",
    "    \n",
    "    def _decode_action_description(self):\n",
    "        pass\n",
    "    \n",
    "    def _decode_image(self):\n",
    "        pass\n",
    "    \n",
    "    def _decode_motor_command(self):\n",
    "        pass\n",
    "    \n",
    "    def __get_transposed_convs(self, decoder_hidden_dim, image_size):\n",
    "        tconv1 = nn.ConvTranspose2d(1, 4, 3, 2, 3, 0)\n",
    "        tconv2 = nn.ConvTranspose2d(4, 8, 5, 2, 3, 0)\n",
    "        tconv3 = nn.ConvTranspose2d(8, 16, 7, 2, 4, 1)\n",
    "        tconv4 = nn.ConvTranspose2d(16, 3, 11, 1, 7, 0)\n",
    "\n",
    "        return nn.Sequential(tconv1, tconv2, tconv3, tconv4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c98918-a0fa-4899-a6c9-58c40e14cdd8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### AEJEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835a6e30-c0cc-49f9-99fc-3f548461c91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AutoencoderJEPS(nn.Module):\n",
    "    \"\"\"\n",
    "    This class is an Autoencoder based deep learning implementation of a Joint Episdoic, Procedural, and Semantic Memory.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, cfg: Dict):\n",
    "        super().__init__()\n",
    "        self.encoder = JEPSAMEncoder()\n",
    "        self.decoder = JEPSAMDecoder()\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        enc = \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d812319-6ca5-4bbf-858e-811df925a093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29defbab-27f7-4374-93a8-e60d8fdca6f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1273fbac-744d-41e1-a244-9b5ee67b0b10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685388a6-cf28-4bc4-99cb-922bc75726c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f93092-89e9-416b-81f2-e6fa53cef1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b246a59c-0ccc-4f63-8208-2d768750528d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
