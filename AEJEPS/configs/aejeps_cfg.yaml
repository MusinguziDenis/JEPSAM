AEJEPS:
  ## Encoder
  EMBEDDING_DIM         : 256                # Embedding dimension of the text embedding module in AEJEPS
  HIDDEN_DIM            : 256                   # The encoder's hidden representation size
  CNN_FC_DIM            : 256
  NUM_LAYERS_ENCODER    : 2             # The number of layers in the Encoder LSTM
  BATCH_FIRST           : True                 # Whether the first dimension is the batch dimension or the time dimension changing this requires significant changes to architectures of many of the models
  ENCODER_DROPOUT       : 0.35              #
  IS_BIDIRECTIONAL      : True       # Whether to process the encoder input sequence in both directions or in left-to-right manner
  
  
  ## Decoder
  ### Action desc
  NUM_LAYERS_MOTOR      : 2               # Number of layers in motor decoder, changing this requires significant changes to decoder implementation
  ACTIVATION_MOTOR      : 'Tanh'          # Only important if switching the LSTMs in AEJEPS to Vanilla RNN
  MOTOR_DROPOUT         : 0.25                # Only important if switching the LSTMs in AEJEPS to Vanilla RNN
  
  ### Motor cmd
  NUM_LAYERS_LANG       : 2                # Number of layers in motor decoder, changing this requires significant changes to decoder implementation
  ACTIVATION_LANG       : 'Tanh'           # Only important if switching the LSTMs in AEJEPS to Vanilla RNN
  LANG_DROPOUT          : 0.25 

  ### Image decoder
  HIDDEN_TO_CONV        : 1024
  DECODER_ACTIVATION    : "Tanh"


DATASET:
  PATH                  : "../dataset/"         
  VOCABULARY_SIZE       : 65 # number of unique  words in the dataset
  IMAGE_SIZE            : 224  # Image size
  SOS                   : 48    # [SOS] token index in vocabulary
  EOS                   : 46    # [EOS] token index in vocabulary
  PAD                   : 47
  TOKENIZER_PATH        : "../dataset/jeps_tokenizer.json"
  ACTION_DESC_MAX_LEN   : 64
  CMD_MAX_LEN           : 128
  VALIDATION_PCT        : .3
  NUM_COMMANDS          : 46   # The number of motor commands in the dataset
  TRAIN_TFMS        : {
        "Resize"                  : {"height": 224,"width": 224},
        "RandomBrightnessContrast": {'p': 0.2},
  }
  TEST_TFMS        : {
        "Resize"                  : {"height": 224,"width": 224},
  }  
TRAIN:
  BATCH_SIZE        : 8    # Batch size to use when training the dataset
  MAX_EPOCH         : 1 #500   # The maximum number epochs to train the model for
  GPU               : True  # Whether to use GPU or not when it is available
  GPU_DEVICE        : "cuda:0"
  NUM_WORKERS       : 4

MODEL:
  CNN_BACKBONES      : {
    "resnet18"        : "ResNet18_Weights.IMAGENET1K_V1",
    "resnet34"        : "ResNet34_Weights.IMAGENET1K_V1",
    "resnet50"        : "ResNet50_Weights.IMAGENET1K_V1",
    "convnext_tiny"   : "ConvNeXt_Tiny_Weights.IMAGENET1K_V1",
    "efficientnet_b4" : "EfficientNet_B4_Weights.IMAGENET1K_V1"

  }
  LEARNING_RATE     : 1e-2                  # The learning rate that will be used by optimizer(s)
  REDUCTION         : mean                      # Computes the mean of the loss over a batch of data as a loss (can also be sum)
  CHECKPOINT_DIR    : "../checkpoints/"         # The directory where checkpoints are to be saved
  OPTIMIZER         : "Adam" 
  LOSS_TYPE         : "cross_entropy"
  LOSS_W            : [1., 1., 1.]

RUN:
  MODE: train_aejeps

WANDB:
  PROJECT_ID        : ""
  GROUP             : ""
  USERNAME          : ""
