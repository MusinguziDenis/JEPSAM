{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7e9b501-631a-44b5-9dd7-b32d94a7a207",
   "metadata": {},
   "source": [
    "# I/O check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a0da5df-63e1-470a-864f-762c294a02bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T07:40:23.843068Z",
     "iopub.status.busy": "2023-08-06T07:40:23.842549Z",
     "iopub.status.idle": "2023-08-06T07:40:24.114097Z",
     "shell.execute_reply": "2023-08-06T07:40:24.111633Z",
     "shell.execute_reply.started": "2023-08-06T07:40:23.843016Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug  6 09:40:23 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.199.02   Driver Version: 470.199.02   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   65C    P5    13W /  N/A |    755MiB /  6069MiB |     19%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1496      G   /usr/lib/xorg/Xorg                 59MiB |\n",
      "|    0   N/A  N/A      2936      G   /usr/lib/xorg/Xorg                274MiB |\n",
      "|    0   N/A  N/A      3150      G   /usr/bin/gnome-shell               67MiB |\n",
      "|    0   N/A  N/A      3380      G   /opt/freedownloadmanager/fdm        1MiB |\n",
      "|    0   N/A  N/A      4142      G   ...RendererForSitePerProcess       35MiB |\n",
      "|    0   N/A  N/A      7002      G   ...507068881159711821,262144      163MiB |\n",
      "|    0   N/A  N/A      7286      G   ...RendererForSitePerProcess      106MiB |\n",
      "|    0   N/A  N/A     16198      G   ...RendererForSitePerProcess       34MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2486d117-7f65-45e1-b4ed-ad7e7a4f67c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T07:40:24.120459Z",
     "iopub.status.busy": "2023-08-06T07:40:24.117063Z",
     "iopub.status.idle": "2023-08-06T07:40:24.275619Z",
     "shell.execute_reply": "2023-08-06T07:40:24.273391Z",
     "shell.execute_reply.started": "2023-08-06T07:40:24.120367Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reload sccripts on change\n",
    "import IPython\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "758f42d2-b11c-4c4d-a3cf-de022f8b1786",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T07:40:24.278892Z",
     "iopub.status.busy": "2023-08-06T07:40:24.278217Z",
     "iopub.status.idle": "2023-08-06T07:40:24.366906Z",
     "shell.execute_reply": "2023-08-06T07:40:24.364603Z",
     "shell.execute_reply.started": "2023-08-06T07:40:24.278826Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import scripts\n",
    "import sys\n",
    "sys.path.append(\"../src/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe89b690-36cd-4810-9e84-b0c330a3ee63",
   "metadata": {},
   "source": [
    "# Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14cd7180-e1e8-4cfe-94ac-1c3d282ed754",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T07:40:30.459836Z",
     "iopub.status.busy": "2023-08-06T07:40:30.458867Z",
     "iopub.status.idle": "2023-08-06T07:40:32.248412Z",
     "shell.execute_reply": "2023-08-06T07:40:32.247437Z",
     "shell.execute_reply.started": "2023-08-06T07:40:30.459737Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85932857-7774-4c37-a881-eff97ea32cb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T07:40:32.249734Z",
     "iopub.status.busy": "2023-08-06T07:40:32.249393Z",
     "iopub.status.idle": "2023-08-06T07:40:33.140291Z",
     "shell.execute_reply": "2023-08-06T07:40:33.139545Z",
     "shell.execute_reply.started": "2023-08-06T07:40:32.249713Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from config import Config as cfg\n",
    "from jepsam_tokenizer import SimpleTokenizer\n",
    "import vocabulary as vocab\n",
    "\n",
    "from dataloader import get_dataloaders,SimpleJEPSAMDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975d1544-0fba-4a7d-99ae-ab08d8106e87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7419a50-3810-4e48-8f06-fab216be22a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9803e086-ac50-42ae-b4ac-d9c3f0b22ad1",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3afa1195-eb56-4969-9718-a950033aa821",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T07:40:35.851557Z",
     "iopub.status.busy": "2023-08-06T07:40:35.850555Z",
     "iopub.status.idle": "2023-08-06T07:40:35.983587Z",
     "shell.execute_reply": "2023-08-06T07:40:35.982801Z",
     "shell.execute_reply.started": "2023-08-06T07:40:35.851478Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_ID</th>\n",
       "      <th>in_state</th>\n",
       "      <th>goal_state</th>\n",
       "      <th>validator</th>\n",
       "      <th>action_description</th>\n",
       "      <th>motor_cmd</th>\n",
       "      <th>len_action_desc</th>\n",
       "      <th>len_motor_cmd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>amihretu</td>\n",
       "      <td>put the :BOTTLE to the left of :BOTTLE</td>\n",
       "      <td>:BOTTLE BLUE POSE-9 :BOTTLE RED POSE-2 :BOTTLE...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1011</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>amihretu</td>\n",
       "      <td>move the :BOTTLE left</td>\n",
       "      <td>:BOTTLE BLUE POSE-3 :BOTTLE  #'*leftward-trans...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1012</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>amihretu</td>\n",
       "      <td>put the :BOTTLE to the right of :MUG</td>\n",
       "      <td>:BOTTLE BLUE POSE-7 :MUG RED POSE-3 :BOTTLE  #...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1013</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>amihretu</td>\n",
       "      <td>shift the :CUP backwards</td>\n",
       "      <td>:CUP RED POSE-4 :CUP  #'*backward-transformati...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>amihretu</td>\n",
       "      <td>shift the :BOTTLE forwards</td>\n",
       "      <td>:BOTTLE GREEN POSE-3 :BOTTLE  #'*forward-trans...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_ID  in_state  goal_state validator  \\\n",
       "0       1005         0           9  amihretu   \n",
       "1       1011         0           9  amihretu   \n",
       "2       1012         0           9  amihretu   \n",
       "3       1013         0           9  amihretu   \n",
       "4       1015         0           9  amihretu   \n",
       "\n",
       "                       action_description  \\\n",
       "0  put the :BOTTLE to the left of :BOTTLE   \n",
       "1                   move the :BOTTLE left   \n",
       "2    put the :BOTTLE to the right of :MUG   \n",
       "3                shift the :CUP backwards   \n",
       "4              shift the :BOTTLE forwards   \n",
       "\n",
       "                                           motor_cmd  len_action_desc  \\\n",
       "0  :BOTTLE BLUE POSE-9 :BOTTLE RED POSE-2 :BOTTLE...                8   \n",
       "1  :BOTTLE BLUE POSE-3 :BOTTLE  #'*leftward-trans...                4   \n",
       "2  :BOTTLE BLUE POSE-7 :MUG RED POSE-3 :BOTTLE  #...                8   \n",
       "3  :CUP RED POSE-4 :CUP  #'*backward-transformati...                4   \n",
       "4  :BOTTLE GREEN POSE-3 :BOTTLE  #'*forward-trans...                4   \n",
       "\n",
       "   len_motor_cmd  \n",
       "0             11  \n",
       "1              8  \n",
       "2             11  \n",
       "3              8  \n",
       "4              8  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf = pd.read_csv(\n",
    "    osp.join(cfg.DATASET['PATH'], \"v1/updated_train.csv\")\n",
    ")\n",
    "\n",
    "tdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a0e949d-aaac-432c-9f03-cdcdf744406b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T07:40:37.459011Z",
     "iopub.status.busy": "2023-08-06T07:40:37.457388Z",
     "iopub.status.idle": "2023-08-06T07:40:37.576792Z",
     "shell.execute_reply": "2023-08-06T07:40:37.575156Z",
     "shell.execute_reply.started": "2023-08-06T07:40:37.458930Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_ID</th>\n",
       "      <th>in_state</th>\n",
       "      <th>goal_state</th>\n",
       "      <th>validator</th>\n",
       "      <th>action_description</th>\n",
       "      <th>motor_cmd</th>\n",
       "      <th>len_action_desc</th>\n",
       "      <th>len_motor_cmd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>3883</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>mdanso</td>\n",
       "      <td>shift the :CEREAL left</td>\n",
       "      <td>:CEREAL RED POSE-10 :CEREAL  #'*leftward-trans...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>dmusingu</td>\n",
       "      <td>put the :BOTTLE in front of :BUTTERMILK</td>\n",
       "      <td>:BOTTLE GREEN POSE-8 :BUTTERMILK RED POSE-4 :B...</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>2887</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>cmanouan</td>\n",
       "      <td>put the :CEREAL behind :BUTTERMILK</td>\n",
       "      <td>:CEREAL RED POSE-13 :BUTTERMILK GREEN POSE-10 ...</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>1455</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>amihretu</td>\n",
       "      <td>put the :BOTTLE in front of :CEREAL</td>\n",
       "      <td>:BOTTLE RED POSE-9 :CEREAL BLUE POSE-2 :BOTTLE...</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>2113</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>cmanouan</td>\n",
       "      <td>move the :BOWL right</td>\n",
       "      <td>:BOWL BLUE POSE-1 :BOWL  #'*rightward-transfor...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sample_ID  in_state  goal_state validator  \\\n",
       "1441       3883         0           9    mdanso   \n",
       "1725        500         0           9  dmusingu   \n",
       "914        2887         0           9  cmanouan   \n",
       "212        1455         0           9  amihretu   \n",
       "516        2113         0           9  cmanouan   \n",
       "\n",
       "                           action_description  \\\n",
       "1441                   shift the :CEREAL left   \n",
       "1725  put the :BOTTLE in front of :BUTTERMILK   \n",
       "914        put the :CEREAL behind :BUTTERMILK   \n",
       "212       put the :BOTTLE in front of :CEREAL   \n",
       "516                      move the :BOWL right   \n",
       "\n",
       "                                              motor_cmd  len_action_desc  \\\n",
       "1441  :CEREAL RED POSE-10 :CEREAL  #'*leftward-trans...                4   \n",
       "1725  :BOTTLE GREEN POSE-8 :BUTTERMILK RED POSE-4 :B...                7   \n",
       "914   :CEREAL RED POSE-13 :BUTTERMILK GREEN POSE-10 ...                5   \n",
       "212   :BOTTLE RED POSE-9 :CEREAL BLUE POSE-2 :BOTTLE...                7   \n",
       "516   :BOWL BLUE POSE-1 :BOWL  #'*rightward-transfor...                4   \n",
       "\n",
       "      len_motor_cmd  \n",
       "1441              8  \n",
       "1725             11  \n",
       "914              11  \n",
       "212              11  \n",
       "516               8  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = 5\n",
    "\n",
    "s = tdf.sample(n=B)\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a0e377f-6c0f-418a-924b-8f961cecf624",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T07:40:39.365286Z",
     "iopub.status.busy": "2023-08-06T07:40:39.364489Z",
     "iopub.status.idle": "2023-08-06T07:40:39.501526Z",
     "shell.execute_reply": "2023-08-06T07:40:39.500775Z",
     "shell.execute_reply.started": "2023-08-06T07:40:39.365214Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['shift the :CEREAL left',\n",
       " 'put the :BOTTLE in front of :BUTTERMILK',\n",
       " 'put the :CEREAL behind :BUTTERMILK',\n",
       " 'put the :BOTTLE in front of :CEREAL',\n",
       " 'move the :BOWL right']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.action_description.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6266b5b6-e65a-47c4-a6b9-a022c5ec7df6",
   "metadata": {},
   "source": [
    "# Model utils\n",
    "\n",
    "1. Episodic embedding `(Module)`\n",
    "2. Semantic embedding `(Module)`\n",
    "3. Sequence (action) encoder `(RNN)`\n",
    "4. Feature mixer `(Linear or RNN)`\n",
    "5. Attention module `(Module)`\n",
    "6. Image generator `(Module)`\n",
    "7. Action generator `(Module)`\n",
    "8. Image reconstructor `(Module)`\n",
    "9. Action description reconstructor `(Module)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58dc54d-346f-46d1-93a3-d9dd2fcc1fc1",
   "metadata": {},
   "source": [
    "#### Episodic embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7de78d79-8f24-4d68-b5ad-d347d495358b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T07:40:44.487437Z",
     "iopub.status.busy": "2023-08-06T07:40:44.487063Z",
     "iopub.status.idle": "2023-08-06T07:40:44.537222Z",
     "shell.execute_reply": "2023-08-06T07:40:44.536425Z",
     "shell.execute_reply.started": "2023-08-06T07:40:44.487404Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.ae_resnet import get_configs, ResNetEncoder, ResNetDecoder\n",
    "\n",
    "class EpisodicEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        cnn_backbone_name:str=\"resnet50\",\n",
    "        hidden_dim:int=cfg.MODEL[\"CNN_FC_DIM\"]\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        configs, bottleneck = get_configs(cnn_backbone_name)\n",
    "        \n",
    "        self.feature_extractor = ResNetEncoder(configs, bottleneck)\n",
    "        \n",
    "        n_ftrs = 2048 * (cfg.IMAGE_SIZE // 32) * (cfg.IMAGE_SIZE // 32)\n",
    "        self.projection_layer = nn.Linear(\n",
    "            in_features=n_ftrs,\n",
    "            out_features=hidden_dim\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x_perceived):\n",
    "        \n",
    "        B, C, H, W = x_perceived.shape\n",
    "        \n",
    "        ftrs = self.feature_extractor(x_perceived)\n",
    "        # print(\"ftrs: \", ftrs.shape)\n",
    "        out = self.projection_layer(ftrs.view(B, -1))\n",
    "        # print(\"out: \", out.shape)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93a14780-f1ed-4515-bf44-2c8d0806816b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T07:40:45.371858Z",
     "iopub.status.busy": "2023-08-06T07:40:45.371046Z",
     "iopub.status.idle": "2023-08-06T07:40:47.293740Z",
     "shell.execute_reply": "2023-08-06T07:40:47.291993Z",
     "shell.execute_reply.started": "2023-08-06T07:40:45.371786Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "======================================================================\n",
       "Layer (type:depth-idx)                        Param #\n",
       "======================================================================\n",
       "EpisodicEncoder                               --\n",
       "├─ResNetEncoder: 1-1                          --\n",
       "│    └─Sequential: 2-1                        --\n",
       "│    │    └─Conv2d: 3-1                       9,408\n",
       "│    │    └─BatchNorm2d: 3-2                  128\n",
       "│    │    └─ReLU: 3-3                         --\n",
       "│    └─EncoderBottleneckBlock: 2-2            --\n",
       "│    │    └─MaxPool2d: 3-4                    --\n",
       "│    │    └─EncoderBottleneckLayer: 3-5       75,008\n",
       "│    │    └─EncoderBottleneckLayer: 3-6       70,400\n",
       "│    │    └─EncoderBottleneckLayer: 3-7       70,400\n",
       "│    └─EncoderBottleneckBlock: 2-3            --\n",
       "│    │    └─EncoderBottleneckLayer: 3-8       379,392\n",
       "│    │    └─EncoderBottleneckLayer: 3-9       280,064\n",
       "│    │    └─EncoderBottleneckLayer: 3-10      280,064\n",
       "│    │    └─EncoderBottleneckLayer: 3-11      280,064\n",
       "│    └─EncoderBottleneckBlock: 2-4            --\n",
       "│    │    └─EncoderBottleneckLayer: 3-12      1,512,448\n",
       "│    │    └─EncoderBottleneckLayer: 3-13      1,117,184\n",
       "│    │    └─EncoderBottleneckLayer: 3-14      1,117,184\n",
       "│    │    └─EncoderBottleneckLayer: 3-15      1,117,184\n",
       "│    │    └─EncoderBottleneckLayer: 3-16      1,117,184\n",
       "│    │    └─EncoderBottleneckLayer: 3-17      1,117,184\n",
       "│    └─EncoderBottleneckBlock: 2-5            --\n",
       "│    │    └─EncoderBottleneckLayer: 3-18      6,039,552\n",
       "│    │    └─EncoderBottleneckLayer: 3-19      4,462,592\n",
       "│    │    └─EncoderBottleneckLayer: 3-20      4,462,592\n",
       "├─Linear: 1-2                                 8,388,864\n",
       "======================================================================\n",
       "Total params: 31,896,896\n",
       "Trainable params: 31,896,896\n",
       "Non-trainable params: 0\n",
       "======================================================================"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epEmb = EpisodicEncoder(cnn_backbone_name=\"resnet50\").cuda()\n",
    "\n",
    "summary(\n",
    "    model=epEmb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86802a80-6219-4afe-aacd-8706d4314233",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T07:40:47.295890Z",
     "iopub.status.busy": "2023-08-06T07:40:47.295555Z",
     "iopub.status.idle": "2023-08-06T07:40:48.379977Z",
     "shell.execute_reply": "2023-08-06T07:40:48.379004Z",
     "shell.execute_reply.started": "2023-08-06T07:40:47.295862Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 256])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = torch.randn((B,3,128,128))\n",
    "\n",
    "ep_emb = epEmb(ex.cuda()).cpu().detach()\n",
    "\n",
    "ep_emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf3052b-ac6c-40b1-b9bd-4b27b8935880",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Semantic Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c710b85b-7cc7-4e77-9d57-e910db658be4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T07:40:48.839455Z",
     "iopub.status.busy": "2023-08-06T07:40:48.835796Z",
     "iopub.status.idle": "2023-08-06T07:40:48.897943Z",
     "shell.execute_reply": "2023-08-06T07:40:48.897036Z",
     "shell.execute_reply.started": "2023-08-06T07:40:48.839372Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([48, 61, 62, 10, 55, 46]),\n",
       " tensor([48, 59, 62,  5, 54, 53, 57,  8, 46]),\n",
       " tensor([48, 59, 62, 10, 51,  8, 46]),\n",
       " tensor([48, 59, 62,  5, 54, 53, 57, 10, 46]),\n",
       " tensor([48, 56, 62,  6, 60, 46])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizer(vocab=vocab)\n",
    "text_ex = s.action_description.values.tolist()\n",
    "\n",
    "tok_text = tokenizer.batch_encode(text_ex)\n",
    "tok_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4736403d-945b-4673-9d45-bf986fb493f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T07:40:50.906091Z",
     "iopub.status.busy": "2023-08-06T07:40:50.905718Z",
     "iopub.status.idle": "2023-08-06T07:40:50.948789Z",
     "shell.execute_reply": "2023-08-06T07:40:50.947221Z",
     "shell.execute_reply.started": "2023-08-06T07:40:50.906062Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 9, 7, 9, 6])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = torch.as_tensor([t.shape[0] for t in tok_text])\n",
    "lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62cf3964-e2cc-471f-a1ef-bc87d2804212",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T07:40:51.685700Z",
     "iopub.status.busy": "2023-08-06T07:40:51.684961Z",
     "iopub.status.idle": "2023-08-06T07:40:51.778871Z",
     "shell.execute_reply": "2023-08-06T07:40:51.776878Z",
     "shell.execute_reply.started": "2023-08-06T07:40:51.685633Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[48, 61, 62, 10, 55, 46, 47, 47, 47]],\n",
       " \n",
       "         [[48, 59, 62,  5, 54, 53, 57,  8, 46]],\n",
       " \n",
       "         [[48, 59, 62, 10, 51,  8, 46, 47, 47]],\n",
       " \n",
       "         [[48, 59, 62,  5, 54, 53, 57, 10, 46]],\n",
       " \n",
       "         [[48, 56, 62,  6, 60, 46, 47, 47, 47]]]),\n",
       " torch.Size([5, 1, 9]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded = pad_sequence(\n",
    "            tok_text, \n",
    "            batch_first=True, \n",
    "            padding_value=cfg.DATASET[\"PAD\"]\n",
    "        ).unsqueeze(1)\n",
    "\n",
    "padded, padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66ac75d-a948-4a48-8ea5-7d8774d3cf0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d225f54f-617d-428a-9689-f427acbc8a23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T07:40:53.034053Z",
     "iopub.status.busy": "2023-08-06T07:40:53.032129Z",
     "iopub.status.idle": "2023-08-06T07:40:53.131887Z",
     "shell.execute_reply": "2023-08-06T07:40:53.126493Z",
     "shell.execute_reply.started": "2023-08-06T07:40:53.033971Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[48, 59, 62,  5, 54, 53, 57,  8, 46],\n",
       "        [48, 59, 62,  5, 54, 53, 57, 10, 46],\n",
       "        [48, 59, 62, 10, 51,  8, 46, 47, 47],\n",
       "        [48, 61, 62, 10, 55, 46, 47, 47, 47],\n",
       "        [48, 56, 62,  6, 60, 46, 47, 47, 47]]), batch_sizes=tensor([5, 5, 5, 5, 5, 5, 3, 2, 2]), sorted_indices=tensor([1, 3, 2, 0, 4]), unsorted_indices=tensor([3, 0, 2, 1, 4]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed = pack_padded_sequence(\n",
    "    input=padded, \n",
    "    lengths= lens, \n",
    "    batch_first=True, \n",
    "    enforce_sorted=False\n",
    ")\n",
    "\n",
    "packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2af5744f-4a42-4042-8892-72c184e4e021",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T07:40:53.880731Z",
     "iopub.status.busy": "2023-08-06T07:40:53.879980Z",
     "iopub.status.idle": "2023-08-06T07:40:53.969181Z",
     "shell.execute_reply": "2023-08-06T07:40:53.967916Z",
     "shell.execute_reply.started": "2023-08-06T07:40:53.880664Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[48, 59, 62,  5, 54, 53, 57,  8, 46],\n",
       "         [48, 59, 62,  5, 54, 53, 57, 10, 46],\n",
       "         [48, 59, 62, 10, 51,  8, 46, 47, 47],\n",
       "         [48, 61, 62, 10, 55, 46, 47, 47, 47],\n",
       "         [48, 56, 62,  6, 60, 46, 47, 47, 47]]),\n",
       " tensor([5, 5, 5, 5, 5, 5, 3, 2, 2]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data, batch_sizes, _, _ = packed\n",
    "input_data, batch_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ab3a722-18c0-48d1-907a-f52809ff63f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T07:40:55.044548Z",
     "iopub.status.busy": "2023-08-06T07:40:55.043783Z",
     "iopub.status.idle": "2023-08-06T07:40:55.140333Z",
     "shell.execute_reply": "2023-08-06T07:40:55.139304Z",
     "shell.execute_reply.started": "2023-08-06T07:40:55.044477Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SemanticEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        vocab_size:int=cfg.DATASET[\"NUM_TOTAL_TOKENS\"], \n",
    "        embedding_dim:int=cfg.MODEL[\"CNN_FC_DIM\"],\n",
    "        num_layers:int=2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=vocab_size, \n",
    "            embedding_dim=embedding_dim,\n",
    "            # padding_idx=cfg.DATASET[\"PAD\"]\n",
    "        )\n",
    "        \n",
    "        self.action_encoder = nn.LSTM(\n",
    "            input_size=embedding_dim, \n",
    "            hidden_size=embedding_dim // 2,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional = True,\n",
    "            batch_first=True\n",
    "        ) \n",
    "\n",
    "    def forward(self, packed_ad, ad_lens):\n",
    "        \n",
    "        # Unpack the packed sequence\n",
    "        input_data, batch_sizes, _, _ = packed_ad\n",
    "        embedded = self.embedding(input_data)\n",
    "        # Pack the embedded sequence back\n",
    "        packed_embedded = pack_padded_sequence(embedded, ad_lens, enforce_sorted=False, batch_first=True)\n",
    "        # Apply LSTM on the packed sequence\n",
    "        packed_output, (h_n, c_n) = self.action_encoder(packed_embedded)\n",
    "        # Unpack the LSTM output\n",
    "        out, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        \n",
    "        return out, h_n, c_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4329d772-f04c-454b-ac7a-38fd50335655",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T07:40:56.400853Z",
     "iopub.status.busy": "2023-08-06T07:40:56.397394Z",
     "iopub.status.idle": "2023-08-06T07:40:56.521599Z",
     "shell.execute_reply": "2023-08-06T07:40:56.520927Z",
     "shell.execute_reply.started": "2023-08-06T07:40:56.400769Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "SemanticEncoder                          --\n",
       "├─Embedding: 1-1                         19,456\n",
       "├─LSTM: 1-2                              790,528\n",
       "=================================================================\n",
       "Total params: 809,984\n",
       "Trainable params: 809,984\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semEmb = SemanticEncoder()\n",
    "    \n",
    "summary(\n",
    "    model=semEmb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df544aa6-6d63-4da6-ac81-cc7661d28ff3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T07:40:57.524297Z",
     "iopub.status.busy": "2023-08-06T07:40:57.523935Z",
     "iopub.status.idle": "2023-08-06T07:40:58.359529Z",
     "shell.execute_reply": "2023-08-06T07:40:58.357500Z",
     "shell.execute_reply.started": "2023-08-06T07:40:57.524264Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 9, 256]), torch.Size([4, 5, 128]), torch.Size([4, 5, 128]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_emb, h_ad, c_ad = semEmb(packed, lens)\n",
    "semantic_emb.shape, h_ad.shape, c_ad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b88bcb4-7ebb-4a81-997d-6be348bfab46",
   "metadata": {},
   "source": [
    "#### Concat operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3db5b00-750c-4473-a56c-3b7d12f0239f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T07:40:59.375010Z",
     "iopub.status.busy": "2023-08-06T07:40:59.374267Z",
     "iopub.status.idle": "2023-08-06T07:40:59.484813Z",
     "shell.execute_reply": "2023-08-06T07:40:59.484062Z",
     "shell.execute_reply.started": "2023-08-06T07:40:59.374942Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 9, 256])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, seq_len, _ = semantic_emb.shape\n",
    "\n",
    "repeated_ep_emb = ep_emb.cpu().detach().unsqueeze(1).expand(\n",
    "    ep_emb.shape[0], \n",
    "    seq_len, \n",
    "    ep_emb.shape[-1]\n",
    ")\n",
    "\n",
    "repeated_ep_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c484abc2-c6f0-4e10-ac81-f46e1fcf4f49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T07:41:00.161362Z",
     "iopub.status.busy": "2023-08-06T07:41:00.158870Z",
     "iopub.status.idle": "2023-08-06T07:41:00.246130Z",
     "shell.execute_reply": "2023-08-06T07:41:00.245309Z",
     "shell.execute_reply.started": "2023-08-06T07:41:00.161274Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 9, 512])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_ftrs = torch.cat((repeated_ep_emb, semantic_emb), dim=-1)\n",
    "\n",
    "concat_ftrs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf5d51c4-7a07-4115-824c-f6c360aca85c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T07:41:01.094005Z",
     "iopub.status.busy": "2023-08-06T07:41:01.093054Z",
     "iopub.status.idle": "2023-08-06T07:41:01.207868Z",
     "shell.execute_reply": "2023-08-06T07:41:01.207269Z",
     "shell.execute_reply.started": "2023-08-06T07:41:01.093929Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(512, 256, num_layers=2, batch_first=True, bidirectional=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_mixer = nn.LSTM(\n",
    "    input_size=cfg.MODEL[\"CNN_FC_DIM\"]*2, \n",
    "    hidden_size=cfg.MODEL[\"CNN_FC_DIM\"],\n",
    "    num_layers= 2,\n",
    "    bidirectional = True,\n",
    "    batch_first=True\n",
    ")\n",
    "\n",
    "feature_mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84aa1813-1676-4376-8780-1697c850ef64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T07:41:02.483950Z",
     "iopub.status.busy": "2023-08-06T07:41:02.483162Z",
     "iopub.status.idle": "2023-08-06T07:41:03.175673Z",
     "shell.execute_reply": "2023-08-06T07:41:03.174285Z",
     "shell.execute_reply.started": "2023-08-06T07:41:02.483882Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 9, 512]), torch.Size([4, 5, 256]), torch.Size([4, 5, 256]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fused_inp, (h, c) = feature_mixer(concat_ftrs)\n",
    "\n",
    "fused_inp.shape, h.shape, c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20e014d-63bd-4165-9ed0-8cc8a8264f8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Attention module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a75b0b4-83ac-466d-8417-314912c8b0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.W_query = nn.Linear(input_dim, hidden_dim)\n",
    "        self.W_key = nn.Linear(input_dim, hidden_dim)\n",
    "        self.W_value = nn.Linear(input_dim, hidden_dim)\n",
    "        self.output_dim = input_dim\n",
    "\n",
    "    def forward(self, query, key, value):\n",
    "        Q = self.W_query(query)\n",
    "        K = self.W_key(key)\n",
    "        V = self.W_value(value)\n",
    "        attention_scores = torch.matmul(Q, K.transpose(-2, -1))\n",
    "        attention_scores = F.softmax(attention_scores, dim=-1)\n",
    "        output = torch.matmul(attention_scores, V)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "class CrossModalAttention(nn.Module):\n",
    "    def __init__(self, ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self):\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48427219-bf5f-48b5-bc0f-37b8f04278dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95de4334-f9c4-4f17-9fc7-2d11dec28fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911a5c3c-9615-4990-8db5-cd841aeea4ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "260898ba-6b21-4ed2-ba1f-3bbc2a0a4d3b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Image generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db19c10-b6f9-4e64-a809-a04b3b78f783",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorCNN(nn.Module):\n",
    "    def __init__(self, latent_dim, output_channels):\n",
    "        super(GeneratorCNN, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.output_channels = output_channels\n",
    "\n",
    "        # CNN layers for the generator\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            latent_dim, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(32, output_channels,\n",
    "                               kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Activation function\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, latent_repr):\n",
    "        # Reshape latent representation to a 4D tensor (batch_size, channels, height, width)\n",
    "        latent_repr = latent_repr.view(\n",
    "            latent_repr.size(0), self.latent_dim, 1, 1)\n",
    "\n",
    "        # Pass the latent representation through the CNN layers\n",
    "        x = self.relu(self.conv1(latent_repr))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        generated_image = self.conv4(x)\n",
    "\n",
    "        return generated_image\n",
    "\n",
    "\n",
    "class ImageGenerationModule(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_channels,\n",
    "        vocab_size,\n",
    "        embedding_dim,\n",
    "        hidden_dim,\n",
    "        output_dim,\n",
    "        motor_commands_dim,\n",
    "        latent_dim\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Attrs\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # Semantic Embedding\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder_lstm = nn.LSTM(embedding_dim + input_channels, hidden_dim)\n",
    "\n",
    "        # Episodic Memory (if applicable)\n",
    "        self.episodic_memory = EpisodicMemory(hidden_dim, hidden_dim)\n",
    "\n",
    "        # Attention Mechanism (if applicable)\n",
    "        self.attention = Attention(hidden_dim, hidden_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.generator = GeneratorCNN(latent_dim, output_dim)\n",
    "\n",
    "    def forward(self, action_desc, initial_state):\n",
    "        # 1. Encode\n",
    "        # Semantic Embedding\n",
    "        embedded_action = self.embedding(action_desc)\n",
    "\n",
    "        concatenated_input = torch.cat((embedded_action, initial_state), dim=1)\n",
    "\n",
    "        # Encoder\n",
    "        encoder_output, (hidden, cell) = self.encoder_lstm(concatenated_input)\n",
    "\n",
    "        # Episodic Memory\n",
    "        episodic_output, _ = self.episodic_memory(encoder_output)\n",
    "\n",
    "        # Attention Mechanism\n",
    "        attended_output = self.attention(\n",
    "            episodic_output, hidden, encoder_output)\n",
    "\n",
    "        # 2. Decode\n",
    "        latent_repr = torch.randn(encoder_output.size(\n",
    "            0), self.latent_dim).to(encoder_output.device)\n",
    "        generated_image = self.generator(latent_repr)\n",
    "\n",
    "        return generated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9808c1fe-01b1-4f07-a7b1-e1f98359e2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4f5c18-003a-490b-9645-d8afad2a1e91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c1b7e8-b5f8-4c49-9aec-34bf0554c9e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "641bdd9f-8300-4589-acba-cdc4048c48d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Action generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c669c36-5237-4102-905c-6c288391e58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionGenerationModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            latent_dim,\n",
    "            output_dim\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1f8db5-47e7-48a9-a6dc-accb7eeef329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db44a3f-93b5-4a82-8790-f6520b772cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8684e3f-bb36-4845-895e-6ce897096c62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c034bd9-ef2f-4d40-9d09-9b12f22ce170",
   "metadata": {
    "tags": []
   },
   "source": [
    "### JEPSAMEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c68bbd98-40db-4fb9-a89e-bccf0149fd80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T10:32:54.543639Z",
     "iopub.status.busy": "2023-07-28T10:32:54.542883Z",
     "iopub.status.idle": "2023-07-28T10:32:54.595322Z",
     "shell.execute_reply": "2023-07-28T10:32:54.594212Z",
     "shell.execute_reply.started": "2023-07-28T10:32:54.543568Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class JEPSAMEncoder(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            vocab_size:int=cfg.DATASET[\"NUM_TOTAL_TOKENS\"], \n",
    "            embedding_dim:int=cfg.MODEL[\"CNN_FC_DIM\"],\n",
    "            num_layers:int=2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Semantic Encoder\n",
    "        self.semantic_encoder = SemanticEncoder(\n",
    "            vocab_size=vocab_size,\n",
    "            num_layers=num_layers,\n",
    "            embedding_dim=embedding_dim\n",
    "        )\n",
    "\n",
    "        # Episodic Encoder\n",
    "        self.episodic_encoder = EpisodicEncoder(hidden_dim=embedding_dim)\n",
    "\n",
    "        # Features mixer\n",
    "        self.feature_mixer = nn.LSTM(\n",
    "            input_size=embedding_dim*2, \n",
    "            hidden_size=embedding_dim,\n",
    "            num_layers= num_layers,\n",
    "            bidirectional = True,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x_ad, x_ad_lens, x_perceived):\n",
    "        # pack padded inputs \n",
    "        packed = pack_padded_sequence(\n",
    "            input=x_ad, \n",
    "            lengths= x_ad_lens, \n",
    "            batch_first=True, \n",
    "            enforce_sorted=False\n",
    "        )\n",
    "        # 1. Semantic Embedding & encoding\n",
    "        semantic_enc, h_ad, c_ad = self.semantic_encoder(packed, x_ad_lens)\n",
    "        _, seq_len, _ = semantic_enc.shape\n",
    "        # logging.info(f\"Semantic encoding: \\t\\t{semantic_enc.shape}\")\n",
    "        \n",
    "        # 2. Episodic encoding\n",
    "        episodic_enc = self.episodic_encoder(x_perceived)\n",
    "        # logging.info(f\"Episodic encoding: \\t\\t{episodic_enc.shape}\")\n",
    "        \n",
    "        repeated_ep_emb = episodic_enc.unsqueeze(1).expand(\n",
    "            episodic_enc.shape[0], \n",
    "            seq_len, \n",
    "            episodic_enc.shape[-1]\n",
    "        )\n",
    "        # logging.info(f\"Repeated embedding: \\t\\t{repeated_ep_emb.shape}\")\n",
    "        # 3. Fusion\n",
    "        concat_ftrs = torch.cat((repeated_ep_emb, semantic_enc), dim=-1)\n",
    "        # logging.info(f\"Concat ftrs: \\t\\t\\t{concat_ftrs.shape}\")\n",
    "\n",
    "        fused_ftrs, (h_fused, c_fused) = self.feature_mixer(concat_ftrs)\n",
    "        # logging.info(f\"Fused features: \\t\\t{fused_ftrs.shape}\")\n",
    "\n",
    "        return fused_ftrs, h_fused, c_fused, h_ad, c_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "16753ac7-9fcb-44c8-85bd-a3a2b18b2386",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T10:34:01.304878Z",
     "iopub.status.busy": "2023-07-28T10:34:01.304588Z",
     "iopub.status.idle": "2023-07-28T10:34:01.646153Z",
     "shell.execute_reply": "2023-07-28T10:34:01.645275Z",
     "shell.execute_reply.started": "2023-07-28T10:34:01.304854Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================================================================\n",
       "Layer (type:depth-idx)                             Param #\n",
       "===========================================================================\n",
       "JEPSAMEncoder                                      --\n",
       "├─SemanticEncoder: 1-1                             --\n",
       "│    └─Embedding: 2-1                              19,456\n",
       "│    └─LSTM: 2-2                                   790,528\n",
       "├─EpisodicEncoder: 1-2                             --\n",
       "│    └─ResNetEncoder: 2-3                          --\n",
       "│    │    └─Sequential: 3-1                        9,536\n",
       "│    │    └─EncoderBottleneckBlock: 3-2            215,808\n",
       "│    │    └─EncoderBottleneckBlock: 3-3            1,219,584\n",
       "│    │    └─EncoderBottleneckBlock: 3-4            7,098,368\n",
       "│    │    └─EncoderBottleneckBlock: 3-5            14,964,736\n",
       "│    └─Linear: 2-4                                 8,388,864\n",
       "├─LSTM: 1-3                                        3,153,920\n",
       "===========================================================================\n",
       "Total params: 35,860,800\n",
       "Trainable params: 35,860,800\n",
       "Non-trainable params: 0\n",
       "==========================================================================="
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jepsam_encoder = JEPSAMEncoder().to(cfg.TRAIN[\"GPU_DEVICE\"])\n",
    "\n",
    "summary(model=jepsam_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a15625d-729f-433d-9b55-ef23aeb40305",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, val_dl = get_dataloaders(\n",
    "    train_df=tdf\n",
    ")\n",
    "\n",
    "# fetch example from dataloader\n",
    "for data in train_dl:\n",
    "    in_state, goal_state, ad, cmd, ad_lens, cmd_lens = data[0], data[1], data[2], data[3], data[4], data[5]\n",
    "    # print(\"In\\t\\t\\t:\", in_state.shape)\n",
    "    # print(\"Action desc\\t\\t:\", ad.shape)\n",
    "    # print(\"Action desc (len)\\t:\", ad_lens.shape)    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "da5deb8a-5737-4d58-86cb-b6059cd28d73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T10:34:04.870475Z",
     "iopub.status.busy": "2023-07-28T10:34:04.869461Z",
     "iopub.status.idle": "2023-07-28T10:34:04.999248Z",
     "shell.execute_reply": "2023-07-28T10:34:04.998154Z",
     "shell.execute_reply.started": "2023-07-28T10:34:04.870397Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input and parameter tensors are not at the same device, found input tensor at cuda:0 and parameter tensor at cpu",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [73]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m E, hn_E, cn_E, hn_ad, cn_ad \u001b[38;5;241m=\u001b[39m \u001b[43mjepsam_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpacked\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jeps/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [68]\u001b[0m, in \u001b[0;36mJEPSAMEncoder.forward\u001b[0;34m(self, x_ad, x_ad_lens, x_perceived)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# 3. Fusion\u001b[39;00m\n\u001b[1;32m     45\u001b[0m concat_ftrs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((repeated_ep_emb, semantic_enc), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m fused_data, h_fused, c_fused \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_mixer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcat_ftrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fused_data, h_fused, c_fused, h_ad, c_ad\n",
      "File \u001b[0;32m~/miniconda3/envs/jeps/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/jeps/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 812\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    815\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    816\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input and parameter tensors are not at the same device, found input tensor at cuda:0 and parameter tensor at cpu"
     ]
    }
   ],
   "source": [
    "# forward through encoder\n",
    "E, hn_E, cn_E, hn_ad, cn_ad = encoder(\n",
    "    x_ad=ad.to(cfg.TRAIN[\"GPU_DEVICE\"]), \n",
    "    x_ad_lens=ad_lens, \n",
    "    x_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5885d93-e8e6-41e3-aa47-8061f2c125ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2376e13-58ec-4dce-91e4-50e7d4059ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899cd708-56cd-4b1a-8f10-b45d6b6396c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51f9a71-4f69-4a74-b36a-3ad12e10fd80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4febe7f9-b6d5-4aee-a4c4-eba91ed96332",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### JEPSAMDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d736e4c-1ea7-4b99-a9be-af46cf825d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6feb66-db34-4bef-9d35-65a50e217a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eed0ef-9603-4b23-9bba-a38e9f412b87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15792394-0209-4f79-bd34-23951af0b40b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af48b69e-6521-4534-a53d-de8d111bbffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3687f3c6-361c-4327-a8d0-429caa176c29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JEPSAM",
   "language": "python",
   "name": "jepsam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
