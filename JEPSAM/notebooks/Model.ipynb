{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7e9b501-631a-44b5-9dd7-b32d94a7a207",
   "metadata": {},
   "source": [
    "# I/O check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a0da5df-63e1-470a-864f-762c294a02bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T09:58:13.134572Z",
     "iopub.status.busy": "2023-07-28T09:58:13.131444Z",
     "iopub.status.idle": "2023-07-28T09:58:13.340897Z",
     "shell.execute_reply": "2023-07-28T09:58:13.338420Z",
     "shell.execute_reply.started": "2023-07-28T09:58:13.134483Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jul 28 11:58:13 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.199.02   Driver Version: 470.199.02   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   63C    P0    25W /  N/A |    375MiB /  6069MiB |      5%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1466      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    0   N/A  N/A      5886      G   /usr/lib/xorg/Xorg                143MiB |\n",
      "|    0   N/A  N/A      6453      G   /usr/bin/gnome-shell               57MiB |\n",
      "|    0   N/A  N/A      6742      G   /opt/freedownloadmanager/fdm        1MiB |\n",
      "|    0   N/A  N/A     29077      G   ...RendererForSitePerProcess       41MiB |\n",
      "|    0   N/A  N/A     40003      G   ...711520412609138250,262144       83MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2486d117-7f65-45e1-b4ed-ad7e7a4f67c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T09:58:13.344356Z",
     "iopub.status.busy": "2023-07-28T09:58:13.343678Z",
     "iopub.status.idle": "2023-07-28T09:58:13.389803Z",
     "shell.execute_reply": "2023-07-28T09:58:13.387619Z",
     "shell.execute_reply.started": "2023-07-28T09:58:13.344283Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reload sccripts on change\n",
    "import IPython\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "758f42d2-b11c-4c4d-a3cf-de022f8b1786",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T09:58:13.394392Z",
     "iopub.status.busy": "2023-07-28T09:58:13.392418Z",
     "iopub.status.idle": "2023-07-28T09:58:13.488350Z",
     "shell.execute_reply": "2023-07-28T09:58:13.486107Z",
     "shell.execute_reply.started": "2023-07-28T09:58:13.394311Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import scripts\n",
    "import sys\n",
    "sys.path.append(\"../src/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe89b690-36cd-4810-9e84-b0c330a3ee63",
   "metadata": {},
   "source": [
    "# Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14cd7180-e1e8-4cfe-94ac-1c3d282ed754",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T10:12:38.255367Z",
     "iopub.status.busy": "2023-07-28T10:12:38.254841Z",
     "iopub.status.idle": "2023-07-28T10:12:38.283441Z",
     "shell.execute_reply": "2023-07-28T10:12:38.282675Z",
     "shell.execute_reply.started": "2023-07-28T10:12:38.255343Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85932857-7774-4c37-a881-eff97ea32cb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T09:58:15.179851Z",
     "iopub.status.busy": "2023-07-28T09:58:15.179574Z",
     "iopub.status.idle": "2023-07-28T09:58:16.086514Z",
     "shell.execute_reply": "2023-07-28T09:58:16.085739Z",
     "shell.execute_reply.started": "2023-07-28T09:58:15.179830Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from config import Config as cfg\n",
    "from jepsam_tokenizer import SimpleTokenizer\n",
    "import vocabulary as vocab\n",
    "\n",
    "from dataloader import get_dataloaders,SimpleJEPSAMDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975d1544-0fba-4a7d-99ae-ab08d8106e87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7419a50-3810-4e48-8f06-fab216be22a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9803e086-ac50-42ae-b4ac-d9c3f0b22ad1",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3afa1195-eb56-4969-9718-a950033aa821",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T09:58:16.088475Z",
     "iopub.status.busy": "2023-07-28T09:58:16.087970Z",
     "iopub.status.idle": "2023-07-28T09:58:16.141772Z",
     "shell.execute_reply": "2023-07-28T09:58:16.140930Z",
     "shell.execute_reply.started": "2023-07-28T09:58:16.088448Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_ID</th>\n",
       "      <th>in_state</th>\n",
       "      <th>goal_state</th>\n",
       "      <th>validator</th>\n",
       "      <th>action_description</th>\n",
       "      <th>motor_cmd</th>\n",
       "      <th>len_action_desc</th>\n",
       "      <th>len_motor_cmd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>amihretu</td>\n",
       "      <td>put the :BOTTLE to the left of :BOTTLE</td>\n",
       "      <td>:BOTTLE BLUE POSE-9 :BOTTLE RED POSE-2 :BOTTLE...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1011</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>amihretu</td>\n",
       "      <td>move the :BOTTLE left</td>\n",
       "      <td>:BOTTLE BLUE POSE-3 :BOTTLE  #'*leftward-trans...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1012</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>amihretu</td>\n",
       "      <td>put the :BOTTLE to the right of :MUG</td>\n",
       "      <td>:BOTTLE BLUE POSE-7 :MUG RED POSE-3 :BOTTLE  #...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1013</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>amihretu</td>\n",
       "      <td>shift the :CUP backwards</td>\n",
       "      <td>:CUP RED POSE-4 :CUP  #'*backward-transformati...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>amihretu</td>\n",
       "      <td>shift the :BOTTLE forwards</td>\n",
       "      <td>:BOTTLE GREEN POSE-3 :BOTTLE  #'*forward-trans...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_ID  in_state  goal_state validator  \\\n",
       "0       1005         0           9  amihretu   \n",
       "1       1011         0           9  amihretu   \n",
       "2       1012         0           9  amihretu   \n",
       "3       1013         0           9  amihretu   \n",
       "4       1015         0           9  amihretu   \n",
       "\n",
       "                       action_description  \\\n",
       "0  put the :BOTTLE to the left of :BOTTLE   \n",
       "1                   move the :BOTTLE left   \n",
       "2    put the :BOTTLE to the right of :MUG   \n",
       "3                shift the :CUP backwards   \n",
       "4              shift the :BOTTLE forwards   \n",
       "\n",
       "                                           motor_cmd  len_action_desc  \\\n",
       "0  :BOTTLE BLUE POSE-9 :BOTTLE RED POSE-2 :BOTTLE...                8   \n",
       "1  :BOTTLE BLUE POSE-3 :BOTTLE  #'*leftward-trans...                4   \n",
       "2  :BOTTLE BLUE POSE-7 :MUG RED POSE-3 :BOTTLE  #...                8   \n",
       "3  :CUP RED POSE-4 :CUP  #'*backward-transformati...                4   \n",
       "4  :BOTTLE GREEN POSE-3 :BOTTLE  #'*forward-trans...                4   \n",
       "\n",
       "   len_motor_cmd  \n",
       "0             11  \n",
       "1              8  \n",
       "2             11  \n",
       "3              8  \n",
       "4              8  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf = pd.read_csv(\n",
    "    osp.join(cfg.DATASET['PATH'], \"v1/updated_train.csv\")\n",
    ")\n",
    "\n",
    "tdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2a0e949d-aaac-432c-9f03-cdcdf744406b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T10:27:37.054637Z",
     "iopub.status.busy": "2023-07-28T10:27:37.053919Z",
     "iopub.status.idle": "2023-07-28T10:27:37.097909Z",
     "shell.execute_reply": "2023-07-28T10:27:37.097271Z",
     "shell.execute_reply.started": "2023-07-28T10:27:37.054585Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_ID</th>\n",
       "      <th>in_state</th>\n",
       "      <th>goal_state</th>\n",
       "      <th>validator</th>\n",
       "      <th>action_description</th>\n",
       "      <th>motor_cmd</th>\n",
       "      <th>len_action_desc</th>\n",
       "      <th>len_motor_cmd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>1701</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>amihretu</td>\n",
       "      <td>put the :CUP in front of :BREAKFAST-CEREAL</td>\n",
       "      <td>:CUP BLUE POSE-8 :BREAKFAST-CEREAL RED POSE-1 ...</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>444</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>dmusingu</td>\n",
       "      <td>move the :BOTTLE forwards</td>\n",
       "      <td>:BOTTLE BLUE POSE-2 :BOTTLE  #'*forward-transf...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>3373</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>mdanso</td>\n",
       "      <td>put the :CEREAL to the right of :CAP</td>\n",
       "      <td>:CEREAL RED POSE-13 :CAP BLUE POSE-10 :CEREAL ...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1166</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>amihretu</td>\n",
       "      <td>move the :BOTTLE backwards</td>\n",
       "      <td>:BOTTLE BLUE POSE-2 :BOTTLE  #'*backward-trans...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>1734</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>amihretu</td>\n",
       "      <td>put the :BOTTLE in front of :SHOE</td>\n",
       "      <td>:BOTTLE GREEN POSE-7 :SHOE BLUE POSE-3 :BOTTLE...</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sample_ID  in_state  goal_state validator  \\\n",
       "324        1701         0           9  amihretu   \n",
       "1699        444         0           9  dmusingu   \n",
       "1009       3373         0           9    mdanso   \n",
       "64         1166         0           9  amihretu   \n",
       "344        1734         0           9  amihretu   \n",
       "\n",
       "                              action_description  \\\n",
       "324   put the :CUP in front of :BREAKFAST-CEREAL   \n",
       "1699                   move the :BOTTLE forwards   \n",
       "1009        put the :CEREAL to the right of :CAP   \n",
       "64                    move the :BOTTLE backwards   \n",
       "344            put the :BOTTLE in front of :SHOE   \n",
       "\n",
       "                                              motor_cmd  len_action_desc  \\\n",
       "324   :CUP BLUE POSE-8 :BREAKFAST-CEREAL RED POSE-1 ...                7   \n",
       "1699  :BOTTLE BLUE POSE-2 :BOTTLE  #'*forward-transf...                4   \n",
       "1009  :CEREAL RED POSE-13 :CAP BLUE POSE-10 :CEREAL ...                8   \n",
       "64    :BOTTLE BLUE POSE-2 :BOTTLE  #'*backward-trans...                4   \n",
       "344   :BOTTLE GREEN POSE-7 :SHOE BLUE POSE-3 :BOTTLE...                7   \n",
       "\n",
       "      len_motor_cmd  \n",
       "324              11  \n",
       "1699              8  \n",
       "1009             11  \n",
       "64                8  \n",
       "344              11  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = 5\n",
    "\n",
    "s = tdf.sample(n=B)\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a0e377f-6c0f-418a-924b-8f961cecf624",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T09:58:16.255249Z",
     "iopub.status.busy": "2023-07-28T09:58:16.254321Z",
     "iopub.status.idle": "2023-07-28T09:58:16.394624Z",
     "shell.execute_reply": "2023-07-28T09:58:16.393871Z",
     "shell.execute_reply.started": "2023-07-28T09:58:16.255193Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['put the :CUP in front of :PLATE',\n",
       " 'put the :FORK to the right of :RED-METAL-PLATE',\n",
       " 'put the :CEREAL to the right of :RED-METAL-PLATE',\n",
       " 'move the :CEREAL left',\n",
       " 'put the :BOTTLE to the left of :RED-METAL-PLATE']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.action_description.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f39b83-ca3f-4bd7-a1bb-51f92564120e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fc6154-4fc0-469d-9d34-b54559b37812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6266b5b6-e65a-47c4-a6b9-a022c5ec7df6",
   "metadata": {},
   "source": [
    "# Model utils\n",
    "\n",
    "1. Episodic embedding `(Module)`\n",
    "2. Semantic embedding `(Module)`\n",
    "3. Sequence (action) encoder `(RNN)`\n",
    "4. Feature mixer `(Linear or RNN)`\n",
    "5. Attention module `(Module)`\n",
    "6. Image generator `(Module)`\n",
    "7. Action generator `(Module)`\n",
    "8. Image reconstructor `(Module)`\n",
    "9. Action description reconstructor `(Module)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58dc54d-346f-46d1-93a3-d9dd2fcc1fc1",
   "metadata": {},
   "source": [
    "#### Episodic embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7de78d79-8f24-4d68-b5ad-d347d495358b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T09:58:28.301178Z",
     "iopub.status.busy": "2023-07-28T09:58:28.300259Z",
     "iopub.status.idle": "2023-07-28T09:58:28.368313Z",
     "shell.execute_reply": "2023-07-28T09:58:28.362018Z",
     "shell.execute_reply.started": "2023-07-28T09:58:28.301123Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.ae_resnet import get_configs, ResNetEncoder, ResNetDecoder\n",
    "\n",
    "class EpisodicEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        cnn_backbone_name:str=\"resnet50\",\n",
    "        hidden_dim:int=cfg.MODEL[\"CNN_FC_DIM\"]\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        configs, bottleneck = get_configs(cnn_backbone_name)\n",
    "        \n",
    "        self.feature_extractor = ResNetEncoder(configs, bottleneck)\n",
    "        \n",
    "        n_ftrs = 2048 * (cfg.IMAGE_SIZE // 32) * (cfg.IMAGE_SIZE // 32)\n",
    "        self.projection_layer = nn.Linear(\n",
    "            in_features=n_ftrs,\n",
    "            out_features=hidden_dim\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x_perceived):\n",
    "        \n",
    "        B, C, H, W = x_perceived.shape\n",
    "        \n",
    "        ftrs = self.feature_extractor(x_perceived)\n",
    "        # print(\"ftrs: \", ftrs.shape)\n",
    "        out = self.projection_layer(ftrs.view(B, -1))\n",
    "        # print(\"out: \", out.shape)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93a14780-f1ed-4515-bf44-2c8d0806816b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T09:58:28.482268Z",
     "iopub.status.busy": "2023-07-28T09:58:28.481472Z",
     "iopub.status.idle": "2023-07-28T09:58:30.103925Z",
     "shell.execute_reply": "2023-07-28T09:58:30.103132Z",
     "shell.execute_reply.started": "2023-07-28T09:58:28.482199Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "======================================================================\n",
       "Layer (type:depth-idx)                        Param #\n",
       "======================================================================\n",
       "EpisodicEncoder                               --\n",
       "├─ResNetEncoder: 1-1                          --\n",
       "│    └─Sequential: 2-1                        --\n",
       "│    │    └─Conv2d: 3-1                       9,408\n",
       "│    │    └─BatchNorm2d: 3-2                  128\n",
       "│    │    └─ReLU: 3-3                         --\n",
       "│    └─EncoderBottleneckBlock: 2-2            --\n",
       "│    │    └─MaxPool2d: 3-4                    --\n",
       "│    │    └─EncoderBottleneckLayer: 3-5       75,008\n",
       "│    │    └─EncoderBottleneckLayer: 3-6       70,400\n",
       "│    │    └─EncoderBottleneckLayer: 3-7       70,400\n",
       "│    └─EncoderBottleneckBlock: 2-3            --\n",
       "│    │    └─EncoderBottleneckLayer: 3-8       379,392\n",
       "│    │    └─EncoderBottleneckLayer: 3-9       280,064\n",
       "│    │    └─EncoderBottleneckLayer: 3-10      280,064\n",
       "│    │    └─EncoderBottleneckLayer: 3-11      280,064\n",
       "│    └─EncoderBottleneckBlock: 2-4            --\n",
       "│    │    └─EncoderBottleneckLayer: 3-12      1,512,448\n",
       "│    │    └─EncoderBottleneckLayer: 3-13      1,117,184\n",
       "│    │    └─EncoderBottleneckLayer: 3-14      1,117,184\n",
       "│    │    └─EncoderBottleneckLayer: 3-15      1,117,184\n",
       "│    │    └─EncoderBottleneckLayer: 3-16      1,117,184\n",
       "│    │    └─EncoderBottleneckLayer: 3-17      1,117,184\n",
       "│    └─EncoderBottleneckBlock: 2-5            --\n",
       "│    │    └─EncoderBottleneckLayer: 3-18      6,039,552\n",
       "│    │    └─EncoderBottleneckLayer: 3-19      4,462,592\n",
       "│    │    └─EncoderBottleneckLayer: 3-20      4,462,592\n",
       "├─Linear: 1-2                                 8,388,864\n",
       "======================================================================\n",
       "Total params: 31,896,896\n",
       "Trainable params: 31,896,896\n",
       "Non-trainable params: 0\n",
       "======================================================================"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epEmb = EpisodicEncoder(cnn_backbone_name=\"resnet50\").cuda()\n",
    "\n",
    "summary(\n",
    "    model=epEmb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "86802a80-6219-4afe-aacd-8706d4314233",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T10:27:41.953773Z",
     "iopub.status.busy": "2023-07-28T10:27:41.953014Z",
     "iopub.status.idle": "2023-07-28T10:27:42.056212Z",
     "shell.execute_reply": "2023-07-28T10:27:42.053884Z",
     "shell.execute_reply.started": "2023-07-28T10:27:41.953702Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 256])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = torch.randn((B,3,128,128))\n",
    "\n",
    "ep_emb = epEmb(ex.cuda()).cpu().detach()\n",
    "\n",
    "ep_emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf3052b-ac6c-40b1-b9bd-4b27b8935880",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Semantic Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c710b85b-7cc7-4e77-9d57-e910db658be4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T10:02:13.151212Z",
     "iopub.status.busy": "2023-07-28T10:02:13.150842Z",
     "iopub.status.idle": "2023-07-28T10:02:13.183508Z",
     "shell.execute_reply": "2023-07-28T10:02:13.182628Z",
     "shell.execute_reply.started": "2023-07-28T10:02:13.151178Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([48, 59, 62, 12, 54, 53, 57, 20, 46]),\n",
       " tensor([48, 59, 62, 13, 63, 62, 60, 57, 22, 46]),\n",
       " tensor([48, 59, 62, 10, 63, 62, 60, 57, 22, 46]),\n",
       " tensor([48, 56, 62, 10, 55, 46]),\n",
       " tensor([48, 59, 62,  5, 63, 62, 55, 57, 22, 46])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizer(vocab=vocab)\n",
    "text_ex = s.action_description.values.tolist()\n",
    "\n",
    "tok_text = tokenizer.batch_encode(text_ex)\n",
    "tok_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4736403d-945b-4673-9d45-bf986fb493f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T10:32:34.836570Z",
     "iopub.status.busy": "2023-07-28T10:32:34.836201Z",
     "iopub.status.idle": "2023-07-28T10:32:34.868195Z",
     "shell.execute_reply": "2023-07-28T10:32:34.867522Z",
     "shell.execute_reply.started": "2023-07-28T10:32:34.836538Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 10, 10,  6, 10])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = torch.as_tensor([t.shape[0] for t in tok_text])\n",
    "lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "62cf3964-e2cc-471f-a1ef-bc87d2804212",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T10:32:36.704196Z",
     "iopub.status.busy": "2023-07-28T10:32:36.703209Z",
     "iopub.status.idle": "2023-07-28T10:32:36.790589Z",
     "shell.execute_reply": "2023-07-28T10:32:36.789693Z",
     "shell.execute_reply.started": "2023-07-28T10:32:36.704120Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[48, 59, 62, 12, 54, 53, 57, 20, 46, 47]],\n",
       " \n",
       "         [[48, 59, 62, 13, 63, 62, 60, 57, 22, 46]],\n",
       " \n",
       "         [[48, 59, 62, 10, 63, 62, 60, 57, 22, 46]],\n",
       " \n",
       "         [[48, 56, 62, 10, 55, 46, 47, 47, 47, 47]],\n",
       " \n",
       "         [[48, 59, 62,  5, 63, 62, 55, 57, 22, 46]]]),\n",
       " torch.Size([5, 1, 10]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded = pad_sequence(\n",
    "            tok_text, \n",
    "            batch_first=True, \n",
    "            padding_value=cfg.DATASET[\"PAD\"]\n",
    "        ).unsqueeze(1)\n",
    "\n",
    "padded, padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66ac75d-a948-4a48-8ea5-7d8774d3cf0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d225f54f-617d-428a-9689-f427acbc8a23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T10:32:40.596911Z",
     "iopub.status.busy": "2023-07-28T10:32:40.596086Z",
     "iopub.status.idle": "2023-07-28T10:32:40.631763Z",
     "shell.execute_reply": "2023-07-28T10:32:40.631027Z",
     "shell.execute_reply.started": "2023-07-28T10:32:40.596833Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[48, 59, 62, 13, 63, 62, 60, 57, 22, 46],\n",
       "        [48, 59, 62, 10, 63, 62, 60, 57, 22, 46],\n",
       "        [48, 59, 62,  5, 63, 62, 55, 57, 22, 46],\n",
       "        [48, 59, 62, 12, 54, 53, 57, 20, 46, 47],\n",
       "        [48, 56, 62, 10, 55, 46, 47, 47, 47, 47]]), batch_sizes=tensor([5, 5, 5, 5, 5, 5, 4, 4, 4, 3]), sorted_indices=tensor([1, 2, 4, 0, 3]), unsorted_indices=tensor([3, 0, 1, 4, 2]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed = pack_padded_sequence(\n",
    "    input=padded, \n",
    "    lengths= lens, \n",
    "    batch_first=True, \n",
    "    enforce_sorted=False\n",
    ")\n",
    "\n",
    "packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2af5744f-4a42-4042-8892-72c184e4e021",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T10:32:41.097036Z",
     "iopub.status.busy": "2023-07-28T10:32:41.096267Z",
     "iopub.status.idle": "2023-07-28T10:32:41.142402Z",
     "shell.execute_reply": "2023-07-28T10:32:41.141501Z",
     "shell.execute_reply.started": "2023-07-28T10:32:41.096965Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[48, 59, 62, 13, 63, 62, 60, 57, 22, 46],\n",
       "         [48, 59, 62, 10, 63, 62, 60, 57, 22, 46],\n",
       "         [48, 59, 62,  5, 63, 62, 55, 57, 22, 46],\n",
       "         [48, 59, 62, 12, 54, 53, 57, 20, 46, 47],\n",
       "         [48, 56, 62, 10, 55, 46, 47, 47, 47, 47]]),\n",
       " tensor([5, 5, 5, 5, 5, 5, 4, 4, 4, 3]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data, batch_sizes, _, _ = packed\n",
    "input_data, batch_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5ab3a722-18c0-48d1-907a-f52809ff63f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T10:32:46.408899Z",
     "iopub.status.busy": "2023-07-28T10:32:46.408074Z",
     "iopub.status.idle": "2023-07-28T10:32:46.441482Z",
     "shell.execute_reply": "2023-07-28T10:32:46.440825Z",
     "shell.execute_reply.started": "2023-07-28T10:32:46.408823Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SemanticEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        vocab_size:int=cfg.DATASET[\"NUM_TOTAL_TOKENS\"], \n",
    "        embedding_dim:int=cfg.MODEL[\"CNN_FC_DIM\"],\n",
    "        num_layers:int=2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=vocab_size, \n",
    "            embedding_dim=embedding_dim,\n",
    "            # padding_idx=cfg.DATASET[\"PAD\"]\n",
    "        )\n",
    "        \n",
    "        self.action_encoder = nn.LSTM(\n",
    "            input_size=embedding_dim, \n",
    "            hidden_size=embedding_dim // 2,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional = True,\n",
    "            batch_first=True\n",
    "        ) \n",
    "\n",
    "    def forward(self, packed_ad, ad_lens):\n",
    "        \n",
    "        # Unpack the packed sequence\n",
    "        input_data, batch_sizes, _, _ = packed_ad\n",
    "        embedded = self.embedding(input_data)\n",
    "        # Pack the embedded sequence back\n",
    "        packed_embedded = pack_padded_sequence(embedded, ad_lens, enforce_sorted=False, batch_first=True)\n",
    "        # Apply LSTM on the packed sequence\n",
    "        packed_output, (h_n, c_n) = self.action_encoder(packed_embedded)\n",
    "        # Unpack the LSTM output\n",
    "        out, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        \n",
    "        return out, h_n, c_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4329d772-f04c-454b-ac7a-38fd50335655",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T10:32:46.765122Z",
     "iopub.status.busy": "2023-07-28T10:32:46.764800Z",
     "iopub.status.idle": "2023-07-28T10:32:46.799876Z",
     "shell.execute_reply": "2023-07-28T10:32:46.799089Z",
     "shell.execute_reply.started": "2023-07-28T10:32:46.765095Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "SemanticEncoder                          --\n",
       "├─Embedding: 1-1                         19,456\n",
       "├─LSTM: 1-2                              790,528\n",
       "=================================================================\n",
       "Total params: 809,984\n",
       "Trainable params: 809,984\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semEmb = SemanticEncoder()\n",
    "    \n",
    "summary(\n",
    "    model=semEmb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "df544aa6-6d63-4da6-ac81-cc7661d28ff3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T10:32:47.115955Z",
     "iopub.status.busy": "2023-07-28T10:32:47.115195Z",
     "iopub.status.idle": "2023-07-28T10:32:47.183548Z",
     "shell.execute_reply": "2023-07-28T10:32:47.182292Z",
     "shell.execute_reply.started": "2023-07-28T10:32:47.115885Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 10, 256]), torch.Size([4, 5, 128]), torch.Size([4, 5, 128]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_emb, h_ad, c_ad = semEmb(packed, lens)\n",
    "semantic_emb.shape, h_ad.shape, c_ad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b88bcb4-7ebb-4a81-997d-6be348bfab46",
   "metadata": {},
   "source": [
    "#### Concat operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e3db5b00-750c-4473-a56c-3b7d12f0239f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T10:32:49.427994Z",
     "iopub.status.busy": "2023-07-28T10:32:49.427617Z",
     "iopub.status.idle": "2023-07-28T10:32:49.467639Z",
     "shell.execute_reply": "2023-07-28T10:32:49.466874Z",
     "shell.execute_reply.started": "2023-07-28T10:32:49.427960Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 256])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, seq_len, _ = semantic_emb.shape\n",
    "\n",
    "repeated_ep_emb = ep_emb.cpu().detach().unsqueeze(1).expand(\n",
    "    ep_emb.shape[0], \n",
    "    seq_len, \n",
    "    ep_emb.shape[-1]\n",
    ")\n",
    "\n",
    "repeated_ep_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c484abc2-c6f0-4e10-ac81-f46e1fcf4f49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T10:32:49.984714Z",
     "iopub.status.busy": "2023-07-28T10:32:49.983900Z",
     "iopub.status.idle": "2023-07-28T10:32:50.051864Z",
     "shell.execute_reply": "2023-07-28T10:32:50.050938Z",
     "shell.execute_reply.started": "2023-07-28T10:32:49.984638Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 512])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_ftrs = torch.cat((repeated_ep_emb, semantic_emb), dim=-1)\n",
    "\n",
    "concat_ftrs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cf5d51c4-7a07-4115-824c-f6c360aca85c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T10:32:50.474211Z",
     "iopub.status.busy": "2023-07-28T10:32:50.473337Z",
     "iopub.status.idle": "2023-07-28T10:32:50.541804Z",
     "shell.execute_reply": "2023-07-28T10:32:50.541096Z",
     "shell.execute_reply.started": "2023-07-28T10:32:50.474133Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(512, 256, num_layers=2, batch_first=True, bidirectional=True)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_mixer = nn.LSTM(\n",
    "    input_size=cfg.MODEL[\"CNN_FC_DIM\"]*2, \n",
    "    hidden_size=cfg.MODEL[\"CNN_FC_DIM\"],\n",
    "    num_layers= 2,\n",
    "    bidirectional = True,\n",
    "    batch_first=True\n",
    ")\n",
    "\n",
    "feature_mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "84aa1813-1676-4376-8780-1697c850ef64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T10:32:51.368727Z",
     "iopub.status.busy": "2023-07-28T10:32:51.368418Z",
     "iopub.status.idle": "2023-07-28T10:32:51.410049Z",
     "shell.execute_reply": "2023-07-28T10:32:51.409154Z",
     "shell.execute_reply.started": "2023-07-28T10:32:51.368706Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 10, 512]), torch.Size([4, 5, 256]), torch.Size([4, 5, 256]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fused_inp, (h, c) = feature_mixer(concat_ftrs)\n",
    "\n",
    "fused_inp.shape, h.shape, c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20e014d-63bd-4165-9ed0-8cc8a8264f8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Attention module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a75b0b4-83ac-466d-8417-314912c8b0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.W_query = nn.Linear(input_dim, hidden_dim)\n",
    "        self.W_key = nn.Linear(input_dim, hidden_dim)\n",
    "        self.W_value = nn.Linear(input_dim, hidden_dim)\n",
    "        self.output_dim = input_dim\n",
    "\n",
    "    def forward(self, query, key, value):\n",
    "        Q = self.W_query(query)\n",
    "        K = self.W_key(key)\n",
    "        V = self.W_value(value)\n",
    "        attention_scores = torch.matmul(Q, K.transpose(-2, -1))\n",
    "        attention_scores = F.softmax(attention_scores, dim=-1)\n",
    "        output = torch.matmul(attention_scores, V)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "class CrossModalAttention(nn.Module):\n",
    "    def __init__(self, ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self):\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48427219-bf5f-48b5-bc0f-37b8f04278dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95de4334-f9c4-4f17-9fc7-2d11dec28fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911a5c3c-9615-4990-8db5-cd841aeea4ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "260898ba-6b21-4ed2-ba1f-3bbc2a0a4d3b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Image generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db19c10-b6f9-4e64-a809-a04b3b78f783",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorCNN(nn.Module):\n",
    "    def __init__(self, latent_dim, output_channels):\n",
    "        super(GeneratorCNN, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.output_channels = output_channels\n",
    "\n",
    "        # CNN layers for the generator\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            latent_dim, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(32, output_channels,\n",
    "                               kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Activation function\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, latent_repr):\n",
    "        # Reshape latent representation to a 4D tensor (batch_size, channels, height, width)\n",
    "        latent_repr = latent_repr.view(\n",
    "            latent_repr.size(0), self.latent_dim, 1, 1)\n",
    "\n",
    "        # Pass the latent representation through the CNN layers\n",
    "        x = self.relu(self.conv1(latent_repr))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        generated_image = self.conv4(x)\n",
    "\n",
    "        return generated_image\n",
    "\n",
    "\n",
    "class ImageGenerationModule(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_channels,\n",
    "        vocab_size,\n",
    "        embedding_dim,\n",
    "        hidden_dim,\n",
    "        output_dim,\n",
    "        motor_commands_dim,\n",
    "        latent_dim\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Attrs\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # Semantic Embedding\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder_lstm = nn.LSTM(embedding_dim + input_channels, hidden_dim)\n",
    "\n",
    "        # Episodic Memory (if applicable)\n",
    "        self.episodic_memory = EpisodicMemory(hidden_dim, hidden_dim)\n",
    "\n",
    "        # Attention Mechanism (if applicable)\n",
    "        self.attention = Attention(hidden_dim, hidden_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.generator = GeneratorCNN(latent_dim, output_dim)\n",
    "\n",
    "    def forward(self, action_desc, initial_state):\n",
    "        # 1. Encode\n",
    "        # Semantic Embedding\n",
    "        embedded_action = self.embedding(action_desc)\n",
    "\n",
    "        concatenated_input = torch.cat((embedded_action, initial_state), dim=1)\n",
    "\n",
    "        # Encoder\n",
    "        encoder_output, (hidden, cell) = self.encoder_lstm(concatenated_input)\n",
    "\n",
    "        # Episodic Memory\n",
    "        episodic_output, _ = self.episodic_memory(encoder_output)\n",
    "\n",
    "        # Attention Mechanism\n",
    "        attended_output = self.attention(\n",
    "            episodic_output, hidden, encoder_output)\n",
    "\n",
    "        # 2. Decode\n",
    "        latent_repr = torch.randn(encoder_output.size(\n",
    "            0), self.latent_dim).to(encoder_output.device)\n",
    "        generated_image = self.generator(latent_repr)\n",
    "\n",
    "        return generated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9808c1fe-01b1-4f07-a7b1-e1f98359e2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4f5c18-003a-490b-9645-d8afad2a1e91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c1b7e8-b5f8-4c49-9aec-34bf0554c9e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "641bdd9f-8300-4589-acba-cdc4048c48d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Action generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c669c36-5237-4102-905c-6c288391e58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionGenerationModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            latent_dim,\n",
    "            output_dim\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1f8db5-47e7-48a9-a6dc-accb7eeef329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db44a3f-93b5-4a82-8790-f6520b772cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8684e3f-bb36-4845-895e-6ce897096c62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c034bd9-ef2f-4d40-9d09-9b12f22ce170",
   "metadata": {
    "tags": []
   },
   "source": [
    "### JEPSAMEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c68bbd98-40db-4fb9-a89e-bccf0149fd80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T10:32:54.543639Z",
     "iopub.status.busy": "2023-07-28T10:32:54.542883Z",
     "iopub.status.idle": "2023-07-28T10:32:54.595322Z",
     "shell.execute_reply": "2023-07-28T10:32:54.594212Z",
     "shell.execute_reply.started": "2023-07-28T10:32:54.543568Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class JEPSAMEncoder(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            vocab_size:int=cfg.DATASET[\"NUM_TOTAL_TOKENS\"], \n",
    "            embedding_dim:int=cfg.MODEL[\"CNN_FC_DIM\"],\n",
    "            num_layers:int=2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Semantic Encoder\n",
    "        self.semantic_encoder = SemanticEncoder(\n",
    "            vocab_size=vocab_size,\n",
    "            num_layers=num_layers,\n",
    "            embedding_dim=embedding_dim\n",
    "        )\n",
    "\n",
    "        # Episodic Encoder\n",
    "        self.episodic_encoder = EpisodicEncoder(hidden_dim=embedding_dim)\n",
    "\n",
    "        # Features mixer\n",
    "        self.feature_mixer = nn.LSTM(\n",
    "            input_size=embedding_dim*2, \n",
    "            hidden_size=embedding_dim,\n",
    "            num_layers= num_layers,\n",
    "            bidirectional = True,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x_ad, x_ad_lens, x_perceived):\n",
    "        \n",
    "        # 1. Semantic Embedding & encoding\n",
    "        semantic_enc, h_ad, c_ad = self.semantic_encoder(x_ad, x_ad_lens)\n",
    "        _, seq_len, _ = semantic_enc.shape\n",
    "        \n",
    "        # 2. Episodic encoding\n",
    "        episodic_enc = self.episodic_encoder(x_perceived)\n",
    "        \n",
    "        repeated_ep_emb = episodic_enc.unsqueeze(1).expand(\n",
    "            episodic_enc.shape[0], \n",
    "            seq_len, \n",
    "            episodic_enc.shape[-1]\n",
    "        )\n",
    "\n",
    "        # 3. Fusion\n",
    "        concat_ftrs = torch.cat((repeated_ep_emb, semantic_enc), dim=-1)\n",
    "        fused_data, h_fused, c_fused = feature_mixer(concat_ftrs)\n",
    "\n",
    "        return fused_data, h_fused, c_fused, h_ad, c_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "16753ac7-9fcb-44c8-85bd-a3a2b18b2386",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T10:34:01.304878Z",
     "iopub.status.busy": "2023-07-28T10:34:01.304588Z",
     "iopub.status.idle": "2023-07-28T10:34:01.646153Z",
     "shell.execute_reply": "2023-07-28T10:34:01.645275Z",
     "shell.execute_reply.started": "2023-07-28T10:34:01.304854Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================================================================\n",
       "Layer (type:depth-idx)                             Param #\n",
       "===========================================================================\n",
       "JEPSAMEncoder                                      --\n",
       "├─SemanticEncoder: 1-1                             --\n",
       "│    └─Embedding: 2-1                              19,456\n",
       "│    └─LSTM: 2-2                                   790,528\n",
       "├─EpisodicEncoder: 1-2                             --\n",
       "│    └─ResNetEncoder: 2-3                          --\n",
       "│    │    └─Sequential: 3-1                        9,536\n",
       "│    │    └─EncoderBottleneckBlock: 3-2            215,808\n",
       "│    │    └─EncoderBottleneckBlock: 3-3            1,219,584\n",
       "│    │    └─EncoderBottleneckBlock: 3-4            7,098,368\n",
       "│    │    └─EncoderBottleneckBlock: 3-5            14,964,736\n",
       "│    └─Linear: 2-4                                 8,388,864\n",
       "├─LSTM: 1-3                                        3,153,920\n",
       "===========================================================================\n",
       "Total params: 35,860,800\n",
       "Trainable params: 35,860,800\n",
       "Non-trainable params: 0\n",
       "==========================================================================="
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jepsam_encoder = JEPSAMEncoder().to(cfg.TRAIN[\"GPU_DEVICE\"])\n",
    "\n",
    "summary(model=jepsam_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "da5deb8a-5737-4d58-86cb-b6059cd28d73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T10:34:04.870475Z",
     "iopub.status.busy": "2023-07-28T10:34:04.869461Z",
     "iopub.status.idle": "2023-07-28T10:34:04.999248Z",
     "shell.execute_reply": "2023-07-28T10:34:04.998154Z",
     "shell.execute_reply.started": "2023-07-28T10:34:04.870397Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input and parameter tensors are not at the same device, found input tensor at cuda:0 and parameter tensor at cpu",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [73]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m E, hn_E, cn_E, hn_ad, cn_ad \u001b[38;5;241m=\u001b[39m \u001b[43mjepsam_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpacked\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jeps/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [68]\u001b[0m, in \u001b[0;36mJEPSAMEncoder.forward\u001b[0;34m(self, x_ad, x_ad_lens, x_perceived)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# 3. Fusion\u001b[39;00m\n\u001b[1;32m     45\u001b[0m concat_ftrs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((repeated_ep_emb, semantic_enc), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m fused_data, h_fused, c_fused \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_mixer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcat_ftrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fused_data, h_fused, c_fused, h_ad, c_ad\n",
      "File \u001b[0;32m~/miniconda3/envs/jeps/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/jeps/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 812\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    815\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    816\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input and parameter tensors are not at the same device, found input tensor at cuda:0 and parameter tensor at cpu"
     ]
    }
   ],
   "source": [
    "E, hn_E, cn_E, hn_ad, cn_ad = jepsam_encoder(packed.cuda(), lens, ex.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5885d93-e8e6-41e3-aa47-8061f2c125ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2376e13-58ec-4dce-91e4-50e7d4059ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899cd708-56cd-4b1a-8f10-b45d6b6396c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51f9a71-4f69-4a74-b36a-3ad12e10fd80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4febe7f9-b6d5-4aee-a4c4-eba91ed96332",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### JEPSAMDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d736e4c-1ea7-4b99-a9be-af46cf825d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6feb66-db34-4bef-9d35-65a50e217a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eed0ef-9603-4b23-9bba-a38e9f412b87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15792394-0209-4f79-bd34-23951af0b40b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af48b69e-6521-4534-a53d-de8d111bbffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3687f3c6-361c-4327-a8d0-429caa176c29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JEPSAM",
   "language": "python",
   "name": "jepsam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
